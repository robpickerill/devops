#+Title: Introduction to Computer Networks
#+Author: Yogesh Agrawal
#+Email: yogeshiiith@gmail.com
#+Date: <2016-07-31 Sun>

* Introduction
  This document discusses about the computer networking concepts
  learnt from Netorking-SP course in [[https://lagunita.stanford.edu/courses/Engineering/Networking-SP/SelfPaced/courseware][edx.org]].

* Connectivity
  Connectivity is the idea that two computers in different parts of
  the world can connect to one another and exchange data. If we
  connect our computer to the internet we suddenly can talk with all
  the other computers connected on the internet.
* Network Applications
  Read and write data over network. Dominant model: bidirectional,
  reliable byte stream connection.
  - One side reads what the other writes
  - Operates in both directions
  - Reliable (unless connection breaks)

  The basic model is: there are two computers each running a program
  locally, and these two programs communicate over the network. The
  most common communication model used is a bidirectional, reliable
  stream of bytes.

* Byte Stream model
  Computer B is waiting for other computers to connect to it. Computer
  A wants to communicate to B. A and B set up a connection. Now when A
  writes data to the connection, B can read it and when B writes data
  to the connection, A can read it. Either side can close the
  connection. Computer A(client) can close the connection, or computer
  B(server) can also close the connection. The error message
  "connection reset by peer", means the server closed the connection
  when client was not expecting it. Server can refuse the connection
  as well, or have a browser wait for a long time because the server
  isn't even responding with a refusal.

* World Wide Web(HTTP)
  The world wide web works using HTTP, which stands for HyperText
  Transfer Protocol.

  In HTTP a client opens a connection to a server and sends commands
  to it. Server after receiving the request checks if client is
  authorized to access the resource, and then sends a response. The
  response also contains a numeric code. There are various types of
  commands such as GET, PUT, DELETE, INFO, as well as other responses
  such as 400 Bad Request. HTTP is all in ASCII text: for example, the
  beginning of a GET request looks like:
  #+BEGIN_EXAMPLE
  GET / HTTP/1.1
  #+END_EXAMPLE
  and the beginning of a response to a successful requests looks like:
  #+BEGIN_EXAMPLE
  HTTP/1.1 200 OK
  #+END_EXAMPLE

  The basic model is simple: client sends a requests by writing to the
  connection, the server reads the request, processes it, and writes a
  response to the connection, which the client then reads.
* Skype
  Unlike the web, where there is a client and a server, in Skype case
  we have two clients. So rather than having a personal computer
  requesting for data from a dedicated server, we have two personal
  computers requesting data from each other. This difference turns out
  to have really big implication to how Skype works.

  The complication comes from NAT, or Network Address
  Translation. NATs are everywhere today. A small home wireless router
  is a NAT. When a mobile phone connects to the internet, it is behind
  a NAT. If a computer is behind NAT, then it can open a connection to
  the internet, but other nodes on the internet can't easily open
  connections to that computer.
  
  Consider a scenario: Client B is behind NAT, Client A is not behind
  NAT. Now client A wants to talk to client B. The complication here
  is that client A, can't open a connection to client B, as it is
  behind NAT. Skype uses Rendezvous server to allow communication in
  such scenario. When we login to Skype, client opens a connection to
  a network of control servers. In this case, client B opens a
  connection to the Rendezvous server. 

  When client A wants to communicate with client B, it tries to
  connect to client B, but it could not. So instead it sends a message
  to a computer to which client B, is already connected to. Which then
  tells client B, that there is a call from A. If client B accepts the
  call, then it opens a connection to client A. Since client A isn't
  behind NAT, this connection can open normally. This is called
  reverse connection, as it reverses the expected direction of
  initiating the connection. when the connection gets established they
  exchange data over that channel.

  When both the clients A and B are behind NATs, we can't reverse the
  connection. Client A can not open connection to client B and client
  B can not open connection to client A. To handle this case Skype
  introduces a second kind of server, called a relay. Relay can't be
  behind NATs. If both client A and client B are behind NATs, then
  they communicate through relay server. They both open connections to
  the relay. When client A sends data, the relay forwards it to client
  B through the connection that B opened. When client B sends data,
  the relay forwards it to client A through the connection that A
  opened.

  A very simple abstraction - a bidirectional and reliable data
  stream, can be used in many interesting ways. By changing how
  programs open connections and what different programs do, we can
  create complex applications.

* Internet 4-layer model
  Applications want to send and receive data without having to worry
  about the path, or route that data takes across the internet. And
  almost all applications also need to be confident that data is
  delivered correctly, with any lost or corrupted data automatically
  retransmitted until is received correctly.

  Four layers are as follows:
  1. Application layer
  2. Transport layer
  3. Network layer
  4. Link layer

  Early internet pioneers designed this four layer model to describe
  the hierarchy of operations that make up the internet, so that
  applications can reuse the same building blocks over and over again
  instead of creating them from scratch for every application.

  It helps to remember that all 4 layers are there to enable reliable
  communication between end-hosts applications. Each layer has a
  different responsibility of building a service on top of the one
  below, all the way to the top where we have bidirectional, reliable
  byte stream communication between applications.

** Link Layer
   Its job is to carry data one link at a time. Data is delivered
   hop-by-hop over each link in turn. Delivers data over a single link
   between an end host and router, or between routers. Ethernet and
   wifi are two examples of link layer. Data is delivered in
   packets. Packet is a self contained unit which contains data to be
   delivered and headers such as - where it came from, where it is
   going and so on.

** Network Layer
   Network layer packets are called datagrams. The network layer hands
   the datagram to the Link layer below, telling it to send the
   datagram over the first link. At the other end of the link is a
   router. The Link layer of the router accepts the datagram and hands
   it up to the network layer. Network layer examines the destination
   address of the datagram, and is responsible for routing the
   datagram one hop at a time, towards its eventual destination. It
   does this by sending it to the Link layer again, and so on until it
   reaches the Network layer at the destination.

   Network layer does not need to concern itself, how link layer
   transmits the data. This also means that single network layer has a
   common way to talk to many different link layers by simply handing
   over the datagrams. 

   This separation of concerns is made possible by the modularity of
   each layer and a common well-define API to the layer below.

   When we send packets to internet we must use Internet Protocol
   (IP). Which provides following features:
   1. Makes best-effort attempt to deliver datagrams to the other end,
      but no promises.
   2. Datagrams may get delivered out of order, may get corrupted, it
      does not provide any guarantees.

** Transport Layer
   If an application wants a guarantee that its data will be
   retransmitted when lost, and will be delivered in order and without
   corruption, then it needs to use another protocol called *Transfer
   Control Protocol (TCP)*, running on top of IP.

   TCP/IP applications uses both TCP and IP together.

   TCP provides a service to application which guarantees correct
   in-order delivery of data, running on top of network layer service,
   which provides an unreliable datagram delivery service. If the
   network layer drops some datagrams, TCP will retransmit them
   multiple times if needed. If the network layer delivers them out of
   order - perhaps because packets follow different path to reach
   destination, TCP will put the data back into the right order again.

   Example of application which uses TCP is email client. These
   applications employ TCP for correct delivery of data. Applications
   don't have to implement their own mechanism for this. They can
   reuse the TCP service, developed by other developers.

   Some applications don't need TCP service. Example: If a video
   streaming application sending a video snippet in a packet, then
   there is no point waiting for packet to be retransmitted multiple
   times, better to just move on. Such applications can use much
   simpler *User Datagram Protocol (UDP)*. UDP bundles application
   data and hands it over to network layer for delivery. UDP offers no
   delivery guarantees.
   
** Application Layer
   While each application is different, it can reuse the Transport
   Layer service using the well-defined API from the application layer
   to the TCP/UDP service beneath.

   Application protocol uses their own syntax and semantics to
   represent data. For example when application requests a page from a
   web server, it sends a GET request to the server. HTTP dictates
   that the GET command be sent as ASCII text. As far as application
   layer is concerned, it send data directly to the application layer
   of the server. Application layer does not need to worry about how
   the data got there, which routes it followed, was there any
   retransmission etc.

* IP
  IP is considered to be a thin waist, because if we want to use
  internet we have to use IP, there is no choice. But IP can be used
  with many different link layers such as wifi, ethernet, 3G etc. On
  top of IP, there can be many different transport layers such as TCP,
  UDP, RTP etc. Similarly it can also be used with many different
  application layers such as HTTP, SSH, FTP, SMTP etc.

  IP datagrams consist of a header and some data. When the transport
  layers has data to send, it hands a Transport Segment to the network
  layer below. The network layer puts the transport segment inside a
  new IP datagram with some header fields. IP's job is to deliver the
  datagram to the other end. But first, it has to make its way to the
  first link to the first router. For this it hands the IP datagram to
  the link layer. Link layer puts the IP datagram inside a Link Frame,
  such as Ethernet packet and ships it off to the first router.

  Datagrams are routed through the network hop by hop, from source to
  the destination. Router contains a routing table which it uses to
  find where to send the packet. Router indexes the table based on the
  destination address and forwards it to the next hop. Hop by hop,
  step by step the packet makes it way from source to the destination
  using only the destination address in the datagram.

  IP datagram service is connectionless, it maintains no state at all
  related to a communication. The communication does not start by
  establishing a end to end connection. For example when we make a
  skype call lasting several minutes, consisting of several IP
  datagrams, the IP layer maintains no knowledge about the call and
  simply routes each datagram packet individually and independent of
  all the others.
 
** IP Service Model
   |----------------+--------------------------------|
   | *Property      | Behaviour*                     |
   |----------------+--------------------------------|
   | Datagram       | Individual packet routing;     |
   |                | Hop-by-hop routing.            |
   |----------------+--------------------------------|
   | Unreliable     | No delivery guarantee;         |
   |                | Packets might be dropped.      |
   |----------------+--------------------------------|
   | Best-effort    | ..but only if necessary        |
   |----------------+--------------------------------|
   | Connectionless | No per-flow state.             |
   |                | Packets might be mis-sequenced |
   |----------------+--------------------------------|
 
   There are various reasons to why IP model was designed to be very
   simple:
   1. To make internet faster, more reliable, lower cost to build and
      maintain. If the network is kept simple, packets can be
      delivered quickly. The simple network can be made to run very
      fast, using dedicated hardware.

   2. The end-to-end principle: It says if we can correctly implement
      a feature at the end host, then we should. The basic idea is to
      place as much intelligence as possible in the end host. It is
      better to implement feature in the software rather than baked
      into the hardware. In internet it was decided that features such
      as congestion control, reliable communications should be
      implemented at the end hosts - by the source and destination
      computers, not by the network.

   3. IP being a unreliable service provides freedom for applications
      to chose to run reliable or unreliable service on top of IP. For
      example real time applications don't need reliable service, if
      any packet is lost in the network, then if re-transmitted packet
      via reliable service is delivered late, it will not be
      useful.

   4. Works over any link layer. IP makes very few assumptions about
      the Link layer below.

** Additional services provided by IP
*** Prevents looping
    IP routers forward packets hop-by-hop, it is possible for the
    routing table in a router to be wrong. In that case packet might
    end up looping between the routers, following the same path. This
    is most likely to happen when the forwarding tables are changing
    and they temporarily get into an inconsistent state.

    IP tries to prevent packets from looping into the network. Rather
    than preventing the loops from ever happening - which would take a
    lot of complexity, it uses a simple technique to catch and delete
    packets that appeared to be stuck in a loop. To do this, IP simply
    adds a hop-count field in the header of every datagram. It is
    called the time to live, or *TTL* field. It starts out with a
    number like 128 and then decremented by 1 by every router it
    passes through. When the value of the TTL reaches 0, router
    concludes that the packet must have been stuck in a loop, hence
    drops the datagram. IP does not guarantee loops won't happen, it
    just tries to limit the damage caused by a flood of endlessly
    looping packets in the network.
    
*** Fragment packets
    IP will fragment the packets if they are too long. IP is designed
    to run on over any kind of link and most links have a limit on the
    size of packets they can carry. For example ethernet can only
    carry packets shorter than 1500 bytes. If an application has more
    than 1500 bytes to send, data has to be broken into 1500 pieces,
    before sending in an IP datagram.

    The size limit between the two links may be different. For example
    router may receive datagrams of size 1500 bytes each, but the
    outgoing link requires packets to be of size 1000 bytes each. In
    that case router will break the datagram into two individual
    datagrams. IP provides header fields which helps router to
    fragment the datagrams into two self-contained IP datagrams and
    reassemble the data correctly again at the end host.

*** Header checksum
    IP uses a header checksum, to prevent delivery of packets at the
    wrong destination. IP includes a checksum field in the datagram
    header, to make sure datagrams are delivered at the right
    location. It is security problem if packets are accidentally and
    frequently sent to the wrong place because of a mistake by the
    router along the way.
*** IP version
    There are two versions of IP protocol - IPv4 and IPv6. IPv4 uses
    32 bit address spaces, and IPv6 uses 128 bit address space. We are
    running out of addresses in IPv4, and IPv6 provides more number of
    addresses. Internet is gradually shifting from IPv4 to IPv6.

*** Add new fields
    IP allows new fields to be added to the datagram header. Adding
    new fields in the header, requires extra processing by the router,
    and router should be able to support that feature. In practise
    very few fields are processed by the router.
** IPv4 Datagram Header
   Following are the important fields in the IPv4 datagram header:
   1. Source address
   2. Destination address
   3. Protocol ID :: This field tells what is inside the data
                     field. It helps end hosts to demultiplex the
                     arriving packets and send to correct code for
                     processing. For example, ID "6" tells the data
                     contains a TCP segment, and so we can safely pass
                     the datagram to the TCP code, and it will be able
                     to parse the segment correctly. The internet
                     assigned number authority defines over 140
                     different values of Protocol ID, representing
                     different transport protocols.
   4. IP version :: Version tells which version of IP is it, whether
                    IPv4 or IPv6.
   5. Packet length :: The total packet length can be upto 64kBytes
                       including header and all the data.
   6. TTL :: Time to live field helps to prevent looping of the
             packets in the network forever. Every router is required
             to decrement the TTL value by 1. If it reaches zero, the
             router should drop the packet.
   7. Packet ID :: The packet-id, flags and fragment offset, all help
                   routers to fragment IP packets into smaller
                   self-contained packets if need-be.
   8. Type of service :: The type of service gives hint to the router
        about how important the packet is.
   9. Header length :: Header length tells us how big the header is.
   10. Checksum :: A checksum is calculated over the whole header, so
                   just in case the header is corrupted, we are not
                   likely to deliver a packet to the wrong destination
                   by mistake.
* TCP Byte stream
** TCP Three way handshake
   Internet 4-layer model takes a stream of data from the application
   layer and hands it to transport layer. Transport layer breaks the
   stream into segments of data that it reliably delivers to
   application running on another computer.

   Client and server does three way handshake to establish a
   connection. A server listens for connection requests, to open a
   connection client issues a connection request.
  
   The first step of handshake is when the client sends a synchronize
   message called "SYN". Second step is when the server responds with
   a synchronize message that is also acknowledgement to the client
   called "SYN-ACK". The third and final step is when client responds
   by acknowledging the server synchronize, called "ACK". So the three
   wat handshake is described as "synchronize, synchronize and
   acknowledge, acknowledge" or "SYN, SYN-ACK, ACK".

** IP address and port
   Network layer responsibility is to deliver packets to the end
   computer. And transport layer responsibility is to deliver data to
   the application. From the network layer perspective, packets sent
   to different application but same computer look the same. So when a
   program wants to talk to another program, we need two
   addresses. The first One is an IP address that is used by the
   network layer to deliver the packet to the end host. Second is
   port, that is used by the transport layer to deliver the data to
   the correct application.

   For example, web servers usually run on port 80. So when we send a
   request to the web server, the packets have destination IP
   address. Those IP packets have TCP segments that has destination
   port 80.

** Router
   A router can have many links connecting to it. As each packet
   arrives, router decides which link to send packet to. A router
   works according to its routing table. Routing table contains set of
   ip addresses patterns and the link to send across for each
   pattern. When a packet arrives at the router, it matches the
   packets against the IP addresses patterns. It finds the best match,
   using longest prefix match algorithm and decides where to forward
   the packet.

   Router itself has an ip address. So router might not forward the
   packet, but deliver to its own software. This happens when we login
   to router over TCP, the IP packets are destined to the router's own
   IP address.

   Router may also contain default route, which is the least specific
   route and matches every IP address. If when a packet arrives and
   there is no specific match, then the default one is used. The
   default route is usually useful in edge networks.

* Packet Switching
  Independently for each arriving packet, pick its outgoing link. If
  the link is free send the packet to that link, else hold the packet
  for later.

** Source routing
   Each packet contains an explicit route, specifying IDs of each
   switch along the path. We call this "self routing" or "source
   routing" because the source specifies the route.

   For example, consider a path : source->A->B->c->destination. When
   the source sends the packet it puts A, B, C, destination ID in the
   packet. When A receives the packet it reads the header and forward
   the packet to B. When B receives the packet it reads the header and
   forward to C, C forwards to the destination. This method of routing
   is called source routing, as source is deciding the path.

   Source routing is supported by the internet, but it is turned
   off. Router owner does not want us to tell how to send the
   packet. This is not considered secure, because someone could trick
   to forward the packet to somewhere where it should not go.

** Optimized routing
   Today's world switches along the path contains a table called
   routing table, that decides where to forward the packet. Switches
   lookup the destination address in the table, and decide where to
   forward the packet. In this model When packet needs to contain the
   destination address.

   For example: consider source wants to send the packet to
   destination. Source puts destination address in the packet and
   sends the packet to next hop A. A sees the packet to be send to
   destination, it then lookups its local table and send the packet to
   B. Similarly B sends it to C and finally packet reaches the
   destination.

** Properties of switch
*** Simple forwarding
    Switch does not maintain state of the packets. It does not care
    whether packet is part of large transfer of a skype call, or its
    just a firmware update for your computer. It just forwards the
    packet individually, independent of each others.
*** Sharing property
    - Flow :: Collection of datagrams belonging to same end-to-end
              communication.

    Switches efficiently share the links between different
    parties. For example suppose two people are browsing the internet
    using the home wireless router. One is reading a page from the
    internet, and the second one can download the file from the
    internet with full speed. When the first one starts loading new a
    web page, the link can be shared among the two. Once the download
    completes the first person can use the full link speed.

    By treating all the traffic as just packets, the wireless router
    can very effectively and simply share the link.

* Encapsulation
** Encapsulation Principle
   We want to breakup data into discrete units, called packets. Each
   packet contains data from multiple layers. Encapsulation is the
   principle by which we organize information in the packet so that we
   can maintain layers, yet let them share the contents of our packets.

   - Layer N data is payload to layer N-1
   - Example:
     + HTTP(application) pay load in
     + a TCP transport segment in
     + an IP network packet in
     + a Wifi link frame

   Each protocol layer has some headers, followed by its payload,
   followed by some footers. For example, IP packet has source address
   and destination address. It has TCP segment as its pay load. IP does
   not care about the payload, it just delivers the packet to the end
   host. When the packet arrives, host looks inside the payload, see
   that its a TCP segment and processes it accordingly.
** Encapsulation Flexibility
   Encapsulation allows to recursively layer protocols. Example:
   =Virtual Private Network (VPN)=, in VPN layering is as follows:
   - HTTP (web) application payload in
   - TCP transport segment in
   - IP network packet in
   - a secured TLS presentation message in
   - TCP transport segment in
   - IP network packet in
   - Ethernet link frame

*** VPN
    VPN is used to open a secure connection to a network we trust,
    such as corporate private network. This is achieved using
    Transport Layer Security protocol (TLS). Instead of sending
    packets to internet normally we send inside the VPN connection, so
    that packets go to office private network. Then this packet is
    routed by end host VPN gateway normally. This lets us access
    private resources of the network. VPN is a single source of
    entrance to the private network, so instead of sprinkle security,
    single node should be made secure, and restricted to allowed
    clients.

    In VPN, client generates packet with HTTP request, that is
    encapsulated inside TCP segment, and then inside IP packet
    destined to company's internal web server. We can not directly
    communicate with the internal web server. So computer puts this
    inside a TLS segment. TLS protects the message and keep it
    secret. Then this TLS session is inside TCP segment, that
    terminates at the virtual private gateway. This is then
    encapsulated inside IP packet destined to the vpn gateway and then
    ethernet frame.
    
* Byte order and packet formats
  Multibyte value is represented by computer in either big endian
  format or little endian format. In character string representation,
  endianness does not effect the layout, because each character is one
  byte.
** Communication
   To generate a message software has to generate a copy of it in
   memory, which is then passed to Network Interface Card. Similarly
   when packet arrives, NIC puts it in memory which is accessed by
   software.
** Little Endian
   Least significant byte is stored at the lowest address.

** Big Endian
   Most significant byte is stored at the lowest address.
** Host order and Network order
   C networking libraries provide functions to convert between host
   order and network order. The function htons() convert host to
   network order. So, the right way to compare port field is to read
   the port field from the packet structure and call ntoshs function
   to convert bytes into host order.
** Packet formats
   Packets are written 4 bytes wide. Since IPV4 has 5 rows of required
   fields, this means that an IPv4 header is at least 20 bytes
   long. The total length field of an IPv4 packet is 2 bytes
   long. This means that an IPv4 packet can't be longer than 65,535
   bytes. When we see an example packet in wireshark, its length could
   be 98, which is 0x0462 in hexadecimal. Packet length is written in
   the big endian format, in the total length field.
* IPv4 Addresses
  The goal of the internet protocol was to take many networks and
  stitch them together. For this to work, protocol needed a way to
  refer to a computer that was independent of the network it was on
  and unique.
  
  An IP address version 4 is 32 bits long. It is represented as
  a.b.c.d, 4 octets. Each device connected to internet has an IP
  address. The IP address uniquely identifies the device in the
  network. In association to the IP address, devices also have
  netmask. Netmask tells the device which IP addresses are local -- on
  the same link -- and which require going through router. For example
  in order to send a packet to another device in the same wireless
  network, the laptop does not need to go through an IP router. It can
  in theory send the packet directly to the other device since it's on
  the same link.
  
  Netmask is written as string of consecutive 1's starting with the
  most significant bit. Netmask is also represented in 4 octets. A
  netmask of 255.255.255.0 for example, means the first 3 octets are
  all 1's, and the last octet is zero. This means that an IP address
  which matches the first three octets is in the same network. A
  netmask of 255.255.252.0 means the netmask is 22 bits long, while
  255.128.0.0 is a 9 bits netmask.

  To compare whether two ips are on the same network or not, we can do
  bitwise 'AND' of the ip address with netmask. If the resulting
  addresses are equal, they are in the same network. For example, ip
  addresses 171.64.15.33 and 171.19.201.2 with netmask 255.255.255.224
  are not in the same network.

* Address Structure
** Address Class
   IP addresses were originally broken up into three classes: Class A,
   Class B and Class C. Each class separated IP address into two
   parts - network address plus host address. Network address is to
   identify the correct network in the internet and host address is to
   identify the correct device in the network.

   Class A,B,C is too coarse grained, meaning they divide the
   addresses into larger components, its not fine grained.

*** Class A
    |------+---------+---------|
    | *Bit | Network | Host*   |
    |------+---------+---------|
    |    0 | 7 bits  | 24 bits |
    |------+---------+---------|

*** Class B
    |------+-----+---------+---------|
    | *Bit | Bit | Network | Host*   |
    |------+-----+---------+---------|
    |    1 |   0 | 14 bits | 16 bits |
    |------+-----+---------+---------|

*** Class C
    |------+-----+-----+---------+--------|
    | *Bit | Bit | Bit | Network | Host*  |
    |------+-----+-----+---------+--------|
    |    1 |   1 |   0 | 21 bits | 8 bits |
    |------+-----+-----+---------+--------|

** Classless Inter Domain Routing - CIDR
   Today we use *Classless Inter-Domain Routing (CIDR)*. Instead of
   having prefixes of length 8, 16 and 24 bits. CIDR allows prefixes
   to be any number of bits. This means all CIDR prefixes define a
   block of addresses that is a power of 2 in size. For example, CIDR
   block as "slash 20" has netmask of length 20. This CIDR block
   describes 2 to the power 12 addresses.
* IPV4 address assignment
  ICANN -> IANA -> Regional Internet Registries (RIR).
* Address Resolution Protocol - (ARP)
  Address resolution protocol is the mechanism by which network layer
  can discover the link address associated with a network address it's
  directly connected to.

  Link layer describes a particular network card, a unique device that
  sends and receives link layer frames. Ethernet for example has 48
  bits unique addresses. IP address says "this host" and link address
  says "this ethernet card".

  Consider following network situation:
  #+BEGIN_EXAMPLE
  A (192.168.0.5; 00:13:72:4c:d9:6a) <--> (192.168.0.1; 0:18:e7:f3:c3:1a) gateway (171.43.22.8; 0:18:e7:f3:ce:1b) <--> (171.43.22.8; 9:9:9:9:9:9) B
  #+END_EXAMPLE

  Node 'A' wants to send packet to node 'B'. 'A' generate IP packets
  with source ip: =192.168.0.5= and destination ip:
  =171.43.22.8=. Node 'A' checks that the destination ip, is not in
  the same network, so it encapsulates the ip packet inside link layer
  frame with source mac address: =00:13:72:4c:d9:6a= and destination
  mac address: =0:18:e7:f3:c3:1a=. Packet reaches the gateway and
  checks destination ip address is not its ip, so it encapsulates the
  ip packet inside a link frame with source mac address:
  =0:18:e7:f3:ce:1b= and destination mac address: =9:9:9:9:9:9=.

  Node 'A' needs to know the link layer address associated to the
  gateway ip address. We need to be able to map layer 3, network layer
  address to the layer 2, link layer address. This is done using ARP
  protocol.

** ARP Packet Format
   ARP packet has 10 fields. The *hardware field* states what link
   layer this request or response is for. The *protocol field* states
   what protocol this request or response is for. The *length* field
   specifies how long the link layer address and network layer
   addresses are. The *opcode* specifies whether the packet is a
   request or response. The *four address fields* are for requesting
   and specifying the mappings.

** ARP request-reply
   ARP is a simple request-reply protocol. Every node keeps a cache of
   mappings from ip addresses on its network to link layer
   addresses. If a node wants to send a packet to ip address it does
   not have a mapping for, it sends ARP request to asking "Who has
   network address x". The node with that address replies, "I have
   network address x". When it receives the reply it generates mapping
   and sends the packet.

   Suppose a client 'A' wants to connect to broader internet, through
   its gateway. But it doesn't have the gateway's Ethernet address.
   - A: Ethernet address - 68:a8:6d:05:85:22, IP address -
     192.168.0.5, IP Netmask - 0xffffff00, IP Gateway - 192.168.0.1.
   - Gateway: Ethernet address - 0:18:e7:f3:ce:1a, IP address -
     192.168.0.1.

*** ARP request
    The client will generate an ARP request whose source address is
    its ethernet address i.e. 68:a8:6d:05:85:22. The destination link
    layer address is the broadcast address - ff:ff:ff:ff:ff:ff all 1s.

    The ARP request will specify that the hardware is Ethernet, which
    is value 1, the protocol is IP, which is value 0x0800, the
    hardware address length is 6, and the protocol length is 4. The
    opcode will be request whose value is 1. The ARP source hardware
    address will be requester's ethernet address:
    68:a8:6d:05:85:22. The source protocol field is the requester's ip
    address: 192.168.0.5. The destination hardware address can be set
    to anything that is what ARP is trying to find out. The
    destination protocol address is the address the client is trying
    to find mapping for: 192.168.0.1. The client sends this frame on
    the Ethernet, every node in the network receives it and refreshes
    its mapping between link address, 68:a8:6d:05:85:22 and its
    network address, 192.168.0.5, or inserts a mapping if does not
    already exists.

*** ARP reply
    The gateway sees that the request is for its IP address and so
    generates a reply.

    Like the request, gateway will specify hardware is ethernet,
    protocol is IP, hardware length is 6, and protocol length
    is 4. The opcode will be reply whose value is 2. The ARP source
    hardware address will be replier's ethernet address:
    0:18:e7:f3:ce:1a. The source protocol address will be:
    192.168.0.1. The destination hardware address is the:
    68:a8:6d:05:85:22 and the destination protocol address will be:
    192.168.0.5.

    It's an open question to what link address this response is to be
    send. It could be send to requester's ethernet address only so
    unicast or it can be broadcasted. Broadcasting the response can
    more aggressively replace cache entries if the mappings needs to
    change. Nodes can also send ARP packets, requesting non-existent
    mappings in order to advertise themselves on a network.

** Node crash
   ARP packet contains redundant data - network and link layer address
   of the requester. So that when nodes receives the request, they can
   insert/refresh entry in their cache. Nodes *only* responds to
   requests for themselves. This means assuming no node is generating
   incorrect packets, the only way a node can generate a mapping for
   another node is in response to a packet that node sends. So, if a
   node crashes or disconnects, its state will inevitably leave the
   network when all of the cached mappings expire. This makes
   debugging and troubleshooting ARP much easier.

** ARP cache time out
   ARP cache expires, within a limited time period. For example Mac
   OSX, keeps state around for 20 minutes. Cisco devices use timeouts
   of 4 hours. These mappings do not change very frequently.
* Transmission Control Protocol
  The Transmission Control Protocol - which is used by over 95% of
  Internet applications. TCP is almost universally used, because it
  provides the reliable, end-to-end, bi-directional byte-stream
  service that almost all applications want.
  
  TCP is an example of transport layer. When an application wants to
  use TCP, it hands some bytes to TCP layer. TCP places these bytes
  into a TCP segment. Then it hands this segment to IP layer, which
  encapsulates the segment in IP datagram. IP hands this datagram to
  link layer, which encapsulates the datagram inside the frame with
  the link layer address, for example ethernet address. Link layer
  then puts the data on the wire.

  When two applications use TCP, they establish a two way
  communication channel between the TCP peers at both ends. First TCP
  establishes a communication channel from A to B. Then it establishes
  a channel from B to A.

  We call the two way communication a "connection". At both ends of
  the connection, TCP keeps a state machine to keep track of how the
  connection is doing.

** Connection Setup
   The TCP connection is established using a 3-way hand shake between
   hosts A and B. First of all host A, sends a message to host B
   indicating that the TCP layer at A wants to establish a connection
   with the TCP layer at B. This message is called "SYN" message which
   is short for synchronize, because A also sends a base number it
   will use to identify bytes in the byte stream. If A sends "0", then
   the number will start at 0, if it sends "1000", then the number
   will start at 1000.

   Host B replies with the message "SYN + ACK". B signals an "ACK",
   because B is acknowledging the request sent by A and agreeing to
   establish the communication from A to B. B also sends a "SYN"
   message indicating that TCP layer at B, wants to establish a
   connection with TCP layer at A. It sends a number too indicating
   the starting number for the byte stream.

   Finally, A sends the "ACK" message, acknowledging the B request and
   agreeing to establish a connection from B to A, in the reverse
   direction. The connection is now setup in both directions. They are
   now ready to start sending data to each other.

** Sending data
   Hosts send data to each other as if it is from a continuous stream
   of bytes. The stream of bytes might exist in advance such as static
   web page, or it could be generated on the fly such as recordings
   from camera, either way TCP sees it as a stream of bytes.

   The data from application A is delivered to application B. TCP
   layers on A and B work together to make sure data is delivered
   correctly in order to the application at B. TCP segment may need to
   be retransmitted multiple times, in the case a segment is dropped
   along the way, or if A doesn't receive an acknowledgement.

   The TCP segment can be as small as 1 byte, for example if we are
   typing characters in SSH session, then each character is sent one
   at a time, rather than waiting for the whole segment to fill
   up. This is not very efficient when we have lots of data to send;
   so we can fill the TCP segment all the way up to the maximum IP
   datagram size.

** Connection Teardown
   When A and B, finished sending data to each other they need to
   close the connection. We say they teardown the connection, which
   means they tell each other they are closing the connection and both
   ends can clean up the sate associated with the state machine. 

   When A finished sending data to B, it sends a "FIN" message short
   for "FINISH" to B. B acknowledges that A has no more data to send,
   and stops looking for new data from A. But B might have new data to
   send to A, and is not ready to close down the connection from B to
   A. So the message from B to A carrying the "ACK" can also carry
   some data to send to A. This way communication from A to B is
   closed. But B can keep sending data to A as long as it
   wants. Sometime later when B finished sending data to A, it sends a
   "FIN" message to A, to tell A, they can close the connection. Then
   A replies with the "ACK" that the connection is now closed. Because
   both the directions have finished the connection is now fully
   closed and the state can be fully removed.
** Services provided to application
*** Reliable communication
    TCP provides a reliable stream of bytes between two
    applications. It uses four mechanism to make the communication
    reliable:

**** Acknowledgement
     When a TCP layer receives a packet, it sends an acknowledgement
     to the sender, to let the sender know the data arrived correctly.
   
**** Checksum
     Checksum detects corrupted data. TCP header contains checksum
     field covering header and segment data to detect if the data got
     corrupted along the way, may be due to bit-error on the wire or
     due to faulty memory inside the router.

**** Sequence number
     Sequence number detects missing data. Every segment header
     carries the sequence number, in the stream of bytes - of the
     first byte in the segment. Suppose two hosts agree on the
     starting sequence number to be 1000. Then the first segment will
     have sequence number of 1000. If the segment carries 500 bytes of
     data, then the next segment will carry sequence number
     of 1500. If a segment gets lost, then the sequence number will be
     incorrect and TCP layer knows some data is missing. It could be
     that the segment will arrive later - perhaps taking a longer
     route, or it could have gone missing, in that case sender has to
     resend the data.

**** Flow control
     Flow-control controls overrunning the receiver. If host A is much
     faster than host B, then its possible that host A will overwhelm
     B by sending data so fast that Host B can't keep up. TCP prevents
     this from happening using Flow-control. In TCP, receiver keeps
     telling the sender if it can keep sending the data. More
     specifically it tells sender how much room it has in its buffer
     to accept new data. If at any point receiver is full it tells,
     sender to stop sending more data. When it has space, it tells
     sender to send more data.
*** In-sequence delivery
    TCP delivers the data to the application in the right sequence. In
    other words whatever sequence the segment was delivered from the
    application to TCP layer at host A, this is the same order in
    which segments are delivered from TCP layer at host B to the
    application. If segments arrive out of order, TCP re-sequences
    them to the correct order using the sequence number before
    delivering to the application.
** Services provided to the whole network
   TCP provides a service to the whole network, by controlling the
   congestion. TCP tries to divide the network capacity equally among
   all the TCP connections, using the network.

* TCP Segment Format
  TCP header is much longer and more complicated than IP headers or
  Ethernet headers. This is because the TCP connection is reliable. To
  achieve reliability the two ends of the connection need to exchange
  more information, so they know which bytes have arrived, which are
  missing and the status of the connection.

** Important TCP header fields
*** Destination port
    The destination port tells the TCP layer which application the
    bytes should be delivered to at the other end. When a new
    connection starts up, the application tells TCP which service to
    open a connection with.

*** Source port
    The source port tells the TCP layer at the other end, to which
    port it should send data back. When host B replies, it should put
    the host A's source port as the destination port field for the
    segment travelling from host B to A, so that TCP layer at host A
    can deliver data to the correct application.

    When a new connection starts, the initiator of the connection for
    example Host A, generates a unique source port which
    differentiates the connection from all other connections between
    host A and B, to the same service.
    
*** Sequence number
    Sequence number indicates the position in the byte stream of the
    first byte in the TCP data field. For example, if the initial
    sequence number is 1000, and is the first segment then the
    sequence number would be 1000. If the segment is 500 bytes long,
    then the sequence number in the next segment would be 1,500 and so
    on.

*** Acknowledgement sequence number
    The acknowledgement sequence number tells the other end which byte
    we are expecting next. It also tells that the it has successfully
    received every byte up until the one before this byte number. For
    example if the acknowledgement sequence number is 1001, it means
    that it has received all the bytes upto 1000, and
    including 1000. Now it is expecting 1001 byte. Note that there are
    sequence number for both the directions in a segment. This way TCP
    piggybacks acknowledgement on the data segments travelling in the
    other direction.

*** Checksum
    16-bit checksum is calculated over the entire header and data, and
    helps the receiver to detect corrupt data. For example bit-errors
    on the wire or faulty memory in the router.

*** Header Length
    Header length field tells us how long the TCP header is. The TCP
    options fields are optional. The header length tells us how many
    option fields are present. Usually there are none.

*** Flags
    There are bunch of flags used to signal information from one end
    of the connection to the other end.
    - ACK: This flag tells that the acknowledgement number is valid
      and we are acknowledging the bytes.
    - SYN: This flag tells that this is a synchronize message, which
      is part of the 3-way handshake, to setup the connection.
    - FIN: This flag signals to close the connection of one direction.
    - PSH: This flag signals the TCP layer to deliver the immediately
      upon arrival, to the application. This is useful for short
      segments carrying time-critical data, such as a key stroke. We
      don't want TCP to wait to accumulate many key strokes before
      delivering to the application.

* TCP Connection ID
  A TCP connection is uniquely identified by five pieces of
  information in the TCP and IP headers.
  - Source port
  - Destination port
  - Source IP
  - Destination IP
  - Protocol ID

  The IP source and destination address uniquely identifies the end
  points, and the IP protocol ID of TCP tells us the connection is
  TCP. The TCP source and destination port uniquely identifies the
  application processes on the end host. Together at any instant, all
  5 fields uniquely identify the TCP connection internet-wide.

  The unique ID only holds if few things hold:

** Unique source port
   We need to make sure Host A, the initiator of the connection picks
   the unique source port when connecting to the service at Host B. It
   should not pick the same source port number which is already in use
   by another connection to the same service on Host B. Host A uses a
   simple method to minimize the chances, it increments the source
   port number for every new connection. The field is 16bits, so it
   will make 65536 new connections before the field wraps around.

   There is also a very slight danger that if Host A suddenly creates
   lot of new connections to Host B, the field might still wrap around
   and try to create two connections with the same global ID. If this
   happens the bytes from one connection might become confused with
   the bytes from another connection. This could happen for example,
   if a TCP segment somehow lived for a long time in the network,
   stuck inside a router buffer or circulating in a temporary loop.

   To reduce the chances of confusion, the TCP connections initialize
   with a random initial sequence number to refer to bytes in the byte
   stream. While not totally fool proof, it does reduce the chances of
   confusion. When Host A initiates the connection it declares the
   initial sequence number it will use, to refer to stream of bytes
   from A to B. When B replies and initiates the connection from B to
   A, it supplies its own initial sequence number for the stream of
   bytes from B to A.

   The sequence number in a segment from A to B, includes the sequence
   number of the first byte, offset by the initial sequence
   number. And the ACK sequence number in the segment from B back to
   A, includes the sequence number of the first byte it is expecting
   next, offset by A's initial sequence number.

* TCP port de-multiplexing
  Server uses source port and destination port to de-multiplex the
  different connections. However, these two fields may not be
  sufficient so it uses ip addresses to de-multiplex the connections.

* UDP
  UDP - User Datagram Protocol is used by the applications that don't
  need the guaranteed delivery service of TCP. Either because
  application handles re-transmissions in its own private way or
  because the application just doesn't need reliable delivery.

** UDP Datagram Format
*** Source Port
    Source port indicates which application the data comes from.
*** Destination Port
    Destination port indicates to which application the data is going
    to.
*** Length
    The 16-bit length field specifies the size of the packet header
    plus data, in bytes. The length will be atleast 8-bytes long as
    that is the size of the header.

*** Checksum
    UDP checksum is optional in the header. If it is not included it
    is all zeros. If it is included it is calculated over UDP data and
    the header.

    UDP checksum calculation also includes a portion of IPv4 header as
    well. The calculation includes the source ip address, destination
    ip address and the protocol id. This violate the principle of
    layering. But the rationale is, it allows UDP layer to detect
    datagrams that were delivered to the wrong destination.

** UDP Service model
   |---------------------+--------------------------------|
   | *Property           | Behavior*                      |
   |---------------------+--------------------------------|
   | Connectionless      | No connection established      |
   | Datagram Service    | packets may show up in         |
   |                     | any order                      |
   |---------------------+--------------------------------|
   | Unreliable Delivery | No acknowledgements            |
   |                     | No mechanism to detect missing |
   |                     | or mis-sequenced datagrams     |
   |                     | No flow control                |
   |---------------------+--------------------------------|

   UDP is used by applications that handle re-transmission by
   themselves, or does not care about re-transmission. 

** Applications using UDP
*** DNS
    DNS uses UDP. Client sends DNS request with UDP protocol to
    convert hostname into ip address. The request is self contained in
    one datagram and using UDP makes DNS faster. If the DNS request
    was successful its lightweight and fast, if it was not successful
    the request times out and is resent.
  
*** DHCP
    Dynamic host configuration protocol uses UDP. Computer finds its
    ip address when it joins a network from DHCP server, using UDP.

*** NTP
    Network time protocol uses UDP.
*** Audio and video streaming
    A few real-time streaming audio and video application uses
    UDP. This is much less common that it used to be. Most audio and
    video streams of http today, which uses TCP.

* ICMP
  Making the network layer work:
  - Internet Protocol: Creation of IP datagrams.
  - Router tables: Algorithms to populate routing table.
  - ICMP: Internet control message protocol
    + Communicates network layer information between end hosts and
      routers.
    + Reports errors conditions.
    + Helps us diagnose problems.

** ICMP Service Model
   ICMP runs above the Network Layer, so its a transport layer
   protocol.
   |-------------------+------------------------------------------|
   | *Property         | Behavior*                                |
   |-------------------+------------------------------------------|
   | Reporting Message | Self-contained messages reporting error. |
   |-------------------+------------------------------------------|
   | Unreliable        | Simple datagram service - no retries.    |
   |-------------------+------------------------------------------|

** ICMP Usage
   Tools such as 'ping' and 'traceroute' both rely on ICMP.
*** traceroute
    traceroute works by sending udp datagrams to the end host. It sets
    the *TTL* value to be 1 for first packet, then keep incrementing
    it by one for further datagrams. Router when receives the packet,
    it decrements the ttl value by one, and when it reaches zero,
    router replies with an ICMP error message to the host, indicating
    ttl has expired. This way host gets the addresses of intermediate
    routers.

    It sets the destination port number as random number, so when the
    udp datagram reaches end host, the end host replies with the port
    unreachable icmp error message. This way traceroute knows end host
    is reached.

* End to End Principle
** First Version
   The function in question can be completely and correctly
   implemented only with the knowledge and help of the application at
   the end points of the communication system. Therefore, providing
   that questioned function as a feature of the communication system
   itself is not possible. (Sometimes an incomplete version of the
   function provided by the communication system may be useful as a
   performance enhancement).

*** File Transfer example
    Suppose a file is to be transferred between two computers. The file
    data will pass through several computers between the source and the
    destination.
    #+BEGIN_EXAMPLE
    Source -> C -> D -> E -> Destination
    #+END_EXAMPLE
    Each link - source to C, C to D, D to E and then E to destination
    has error detection. If a packet of data is corrupted in
    transmission, then the recipient can detect this and reject the
    packet. The sender will figure out the packet didn't arrive
    successfully, for example through TCP acknowledgements and resend
    it.

    With this setup, one can claim that the packets won't be corrupted
    at any link, because we have checks. If it will not be corrupted at
    any link, it won't be corrupted. Therefore if it arrives
    successfully at the destination, there's no corruption, and the
    file has been arrived successfully.

    This claim is wrong. Suppose computer D had buggy memory, such that
    sometimes some bit values gets flipped. Packet arrived at D, it
    checked for the error and no error was detected. Then it will move
    the data to main memory, at which point they would become
    corrupted. It would then forward the packet, but because error
    detection occurs on the link, from the link's perspective the
    packet looked fine and it would pass E's check. The link error
    detection was designed for errors in *transmission*, not for errors
    in storage.

    The only way to be sure the file transferred successfully is to
    perform end to end check. When the source sends the file it
    includes some error detection information. When the receiver
    reassembles the file and check whether the file, in its entirety
    has any errors. This is the only way one can be sure it arrived
    successfully. The network can help, but it can't be responsible for
    correctness.

*** TCP example
    TCP is responsible for reliable data delivery. But the reliability
    is not perfect. It's very unlikely that TCP will deliver corrupted
    data to the application. But there is a chance that TCP delivers
    some bad data, for example because there is some bug in our TCP
    stack, or some error creeps in from somewhere. In that case
    applications must perform end to end data check. Bit torrent does
    that, it uses TCP to transfer chunks, and after each chunk is
    complete, it checks that it arrived successfully using a hash.
*** Wireless - performance enhancement
    According to the end to end argument, correctness features should
    be implemented at the end points. The network can include an
    incomplete version of the correctness function as performance
    enhancement but it can't be made responsible.

    Wireless link layer provides such a performance enhancement. Wired
    data transmission is considered to be highly reliable, almost
    99.99% of packets sent on wired link arrive successfully at the
    next hop. Whereas wireless can sometimes be like only 50-80%
    reliable. 

    TCP doesn't work well with low reliability. Thus, to improve
    reliability, wireless link layer re-transmits the packets at the
    link layer. For example when our laptop sends data to access point,
    the access point after receiving the packet immediately -- just a
    few microseconds later -- sends a link layer acknowledgement back
    to the laptop. If the laptop does not receive a link layer
    acknowledgement it re-transmits. It does this several times. These
    link layer acknowledgments can boost the poor link, with 80%
    reliability to 99% or higher. This lets TCP work much better.

** Second Version
   The network's job is to transmit datagrams as efficiently and as
   flexibility as possible. Everything else should be done at fringes.
   If the system is to work correctly then the end points need to be
   responsible for making sure it does. Nobody else has the
   information necessary to do this correctly.

   If the network implements certain piece of functionality at the
   middle. It assumes something about the end applications. For
   example when wireless link layer uses re-transmission to improve
   the reliability so that TCP can work better. It is assuming that
   increased re-transmission latency is worth the reliability. This is
   not always true. There are some protocols that would send a new,
   different packet rather than retry sending an old one. But link
   layer has incorporated these protocols are stuck with it. This can
   and does act as impediment to innovation and progress. As layers
   start to add optimization assuming what the layers above and below
   them do, it becomes harder and harder to redesign the layers. In
   the case of wireless, it's a link layer that assumes certain
   behavior at the network and transport layers.

* Error Detection
  Networks are not perfect and neither are the hosts that run on them,
  they can introduce errors. We need to be able to detect these
  errors.

  At a high level, we have a payload of data, we calculate some error
  detection bits over that data and either append it or prepend it to
  the payload. For example, Ethernet appends a cyclic redundancy code,
  Transport Layer Security appends a message authentication code, and
  IP prepends a checksum, which it places in the IP header.

  There are three algorithms to detect the errors:

** Checksum
   Checksum just adds all of the data in the packet. Checksum are nice
   because they are very fast and cheap to compute, even in
   software. Their major drawbacks is that they provide very weak
   error detection guarantee. It can detect lot of random errors but
   its easy to fool a checksum with as few as 2 bit errors, if the two
   bit errors cancel each other out. For example if one bit error adds
   32 and another bit error subtracts 32, then a checksum won't catch
   the error. This is used by TCP and IP.

** Cyclic Redundancy Code - CRC
   A CRC is much more computationally expensive than a checksum, but
   also much more robust. It computes the remainder of a
   polynomial. It's what Ethernet and many link layers use. In some
   ways, TCP and IP can get away with checksums because the link
   layers use CRCs.
   
** Message Authentication Code - MAC
   Message authentication codes uses cryptography, a branch of
   mathematics that deals with secrets. The idea behind most message
   authentication codes is that the two parties share a secret s. This
   secret is just a set of randomly generated bits (random so it's
   hard to guess). To calculate the message authentication code C,
   apply the MAC algorithm to the message M and the secret s.

   Message authentication codes are very useful, but they're first and
   foremost a security mechanism. Being able to get both error
   detection and security with one mechanism is efficient and nice,
   but their security properties mean their error detection isn't as
   good as other approaches.

* Finite State Machine
  Finite state machine, is composed of a finite number of states. A
  state is a particular configuration of the system.

  State1 -> State2
  - events causing state transition
  - actions taken on state transition

  Edges between the states define how we transition between them. When
  we draw an edge, we first specify what events cause the transition
  to occur. Below this we can state what actions system will take when
  that transitions occurs. This part is optional because not all
  transitions have actions associated with them.
  
  If the system is in a state and an event arrives for which there is
  no transition described, then the behavior of the FSM is undefined.

** HTTP Request
   In our starting state we are either *viewing a page* or
   otherwise *idle*. When we want to load a new page, we transition to
   the *page requesting state*. So the event is load new page, and the
   action is open a connection to the web server. Once we've opened a
   connection, we are now in the page requesting state. We'll
   transition back to the idle state when the connection closes or
   when we finish requesting every resource on the page.

   We need one more state, which describes where we are in requesting
   a page. On the event of having more resources to request, we take
   the action of requesting a resource with an HTTP GET. This puts us
   in the *request pending state*. On the event of receiving the
   response, out system transitions back to the page requesting state.

   So, here we have three states: *idle*, *page requesting*
   and *request pending*.

   On one hand this is a nice, and simple FSM. But if you were to try
   to implement it, it leaves a lot unsaid. Specifically we have 4
   events in the system: page request, more requests, receive
   response, and connection closed. So what happens if the connection
   closes when we're in the request pending state? Or when we receive
   a page request while in the page requesting state? Or receive
   response while in the idle state?

   If we want to completely explicit we should specify what happens on
   each state for every event. But this can lead to complicated FSMs
   which have tons of edges. So often instead we specify only common
   cases for the ease of understanding, and have some supporting text
   about other transitions. Or, in some cases, it can even be
   acceptable to leave something undefined. The Internet Engineering
   Task Force, for example, often doesn't completely specify every
   FSM. The idea is that by specifying only the parts that are
   necessary for interoperability, we can leave the specification
   flexible for future exploration. As people use the protocol, they
   will figure out if something is important and can specify that
   extra part later.

* COMMENT TODO
  1. join emacs group
  2. Understanding the Linux Kernel
  3. Check if we can make two concurrent calls in skype to a user.
  4. Skype works on which port?
  5. How VPN works, connect to VPN and capture packets.
  6. How internal web address is resolved in VPN.
  7. In https every packet will be encrypted, can we see this in
     wireshark.
  8. What does 'route' command does. 
  9. ping 127.0.0.10 replies, how ?
  10. Can network layer takes do compression before sending packets?
  11. ICANN, IANA, APNIC, RIPE NCC
  12. http://news.stanford.edu/news/1999/january27/itss127.html
  13. How many mac addresses are possible in 48bits, are all devices
      in the world have unique mac addresses.
  14. Why is hexadecimal chosen over binary?
  15. Who decides tcp segment data size.
  16. When we open multiple ssh sessions, how does the source port
      number is decided. Is it decided by the application or TCP
      layer.
  17. Any other vs all other.
  18. How does browser identifies different tabs.
  19. How does TCP detects between first and second packet. What if
      second packet reaches destination before first one.
  20. Does TCP sends one packet at a time, receive ack and then second
      packet or it sends multiple packets at once.
  21. Capture DHCP packets, using wireshark.
* COMMENT References
  -
    http://www.enterprisenetworkingplanet.com/netsp/article.php/3593936/Networking-101--Understanding-TCP-the-Protocol.htm
   (TCP)
  -
    https://lagunita.stanford.edu/courses/Engineering/Networking-SP/SelfPaced/courseware
   (stanford course ware)
  - RFC-1958
