#+Title: Linux Foundation Course
#+Author: Yogesh Agrawal
#+Date: <2016-03-19 Sat>
#+Email: yogeshiiith@gmail.com

* Introduction
  This document has the learning which I learn from the Linux
  Foundation Course: LFS101x in edx.

* Linux requirements
  The technical differences are mainly about package management
  systems, software versions, and file locations.
** Key facts about Debian Family
   - The Debian family is upstream for Ubuntu.
   - The Linux Kernel 3.13 is used in Ubuntu 14.04
   - It uses the DPKG-based apt-get package manager to install,
     update, and remove packages in the system.

** Key facts about Fedora Family
   - The fedora family is upstream for CentOS, RHEL, and Oracle Linux.
   - The Linux kernel 2.6.32 is used in RHEL/CentOS 6.x
   - It uses the RPM-based yum package manager to install, update and
     remove packages in the system.

* Linux philosophy
  Linux is derived heavily from UNIX operating system. Files are
  organized in a hierarchical filesystem, with the top node of the
  system being root or =/=. Linux components are made available via
  files or objects that look like files. Processes, devices and
  network sockets are all represented by file-like objects, and can
  often be worked with same utilities used for regular files.

  Linux is a multiuser and multitasking operating system, with built
  in networking and service processes known as daemons in the UNIX
  world.

* Linux terminology
** Kernel
   Kernel is the brain of the Operating System. It controls the
   hardware and make hardware available for applications. Latest Linux
   kernel can be seen from http:://kernel.org site.

** Distribution
   Distribution is the bunch of programs combined together with Linux
   kernel to make a Linux based Operating System. Example are Fedora
   and Debian.

** Boot Loader
   Program that boots the operating system. Example are GRUB and
   ISOLinux.

** Service
   Service is a program that runs as a background process. Example
   httpd, nfsd, ftpd and named.

** Filesystem
   Method for storing and organizing files. Example are ntfs, ext3,
   ext4, FAT, NTFS.

** X Windows System
   Provides toolkit or protocol to build graphical interfaces in
   nearly all Linux system.

** Desktop Environment
   Graphical user interface on top of Linux operating system. Example
   are GNOME and KDE.

** Command Line
   Interface for typing commands on top of the operating system.

** Shell
   Command line interpreter that interprets the command line input and
   instructs the operating system to perform any necessary tasks and
   commands. Example are bash and zshell.
 
* Partitions and Filesystems
  Partition is a logical part of the disk, whereas filesystem is a
  method of storing/finding files on a hard disk. We can think of
  filesystems as being like a family tree and partitions as different
  families each of which as its own tree.

* Filesystem hierarchy standard
  Linux filesystem names are case sensitive, that means =/boot=, =/Boot=
  and =/BOOT= represent three different directories. Many distributions
  distinguish between core utilities needed for proper system operation
  and other programs. So other programs are placed inside =/usr=
  directory. Example of directories inside =/= root directory.
  #+BEGIN_EXAMPLE
  .
  |-- bin
  |-- boot
  |-- cdrom
  |-- dev
  |-- etc
  |-- home
  |-- lib
  |-- lib64
  |-- lost+found
  |-- media
  |-- mnt
  |-- opt
  |-- proc
  |-- root
  |-- run
  |-- sbin
  |-- srv
  |-- sys
  |-- tmp
  |-- usr
  `-- var
  #+END_EXAMPLE

* The Boot Process
  - Boot process is the procedure of initializing the system.

  - Understanding boot process will help in troubleshooting systems
    issues more elegantly.

  - The boot process consists of following 9 steps:
    #+BEGIN_EXAMPLE
    1. Power On
    2. BIOS
    3. MBR - Master Boot Record
    4. Boot Loader
    5. Kernel OS
    6. Init Ramfs
    7. /sbin/init
    8. Shell
    9. Graphics
    #+END_EXAMPLE

** BIOS
   Basic Input/Output System initializes the hardware, including the
   screen and keyboard, and tests the main memory. The BIOS software
   is stored on ROM chip on motherboard. After this the remainder of
   the boot process is completely controlled by the operating system.

** Master boot record
   Searches for the boot loader and loads into the RAM.

** Boot Loader
   Boot loader is stored on the boot sector. Boot loaders present a
   user interface for user to choose from available option of
   operating systems. Boot loader is responsible for loading kernel
   image and the initial RAM disk (which contains some critical files
   and device drivers needed to start the system) into memory.

*** Boot loader in action
    The boot loader resides at the first sector of the hard disk also
    known as the Master Boot Record (MBR). The size of the MBR is just
    512 bytes. Boot loader first finds the bootable partition. Once it
    finds the bootable partition it then searches for the second level
    boot loader - GRUB. It then loads the grub into the main memory.
    
    Boot loader displays options which allows us to choose different
    available operating systems. After choosing the operating system
    boot loader loads the kernel into the main memory and passes
    control to it.
    
    Kernel are always compressed when loaded into main memory so its
    first job is to uncompress itself. After this it will check and
    analyze the system hardware and initialize any hardware device
    driver built into the kernel.

** Linux Kernel
   The boot loader loads the kernel and initial ram file system in the
   main memory. Kernel initializes all hardware systems attached to
   the machine this includes all processors, I/O systems, storage
   devices etc. Kernel also loads some necessary user level
   applications into the main memory.

** /sbin/init process
   Once the kernel has setup all the hardware and mounted the root
   file system, the kernel runs the =/sbin/init= program.
  
   init is responsible for keeping the system running and shutting
   down. It is responsible for all non-kernel processes, cleaning up
   after them when necessary, and restarts user login services as
   needed when using log in and out.

** X Windows system
   We can start the default display manager after logging on to a
   text-mode console, and running *startx* from the command line.

* Linux Installation
** Choosing Distribution
   Questions that are to be asked while choosing Linux distributions:
   - What is the main purpose of the OS, server or desktop ?
   - How much disk space is available ?
   - How often packages are updated in a particular distribution ?
   - What is the architecture of the hardware ?

** Partition
   Decide how we want to partition the disk to install OS. we may
   choose to have separate partition for =/home=, =/var= and =/root=.

** Source of installation
   - optical disk: cd, dvds
   - usb
   - network boot

** Automating installation
   Installation process can be automated using a configuration file
   specifying the installation options. For debian-based system file
   is called =preseed=. Example preseed file is here hosted on
   internet by help-ubuntu community:
   https://help.ubuntu.com/lts/installation-guide/example-preseed.txt

** Restart, sleep and shutdown
   - System asks for confirmation while shutting down because many
     applications do not save their data properly when terminated
     while running.

   - Sleep mode works by keeping the applications, desktop and so on
     in RAM and turning off all other hardware.

* Gnome desktop environment
  - Gnome is popular desktop environment and graphical user interface
    that runs on top of the Linux operating system.
  - Ubuntu has =unity= desktop manager which is based on gnome.
  - "Nautilus" is the file browser in gnome.
  - File manager shows following default directories:
    + HOME directory :: User's home directory
    + Computer :: Different drives attached to the system such as hard
                  disk drives, cd/dvd, usb pendrives etc.
    + Network :: Networked and shared devices such as Network shares,
                 printers and file servers.
  - Removing a file, moves the file to trash folder. Trash folder is
    located at =~/.local/share/Trash/files/=.
  - Logging out kills all processes in our current *X* session and
    returns to the display manager.

* System configuration using graphical interface
** Display settings
   Default configuration is to show a large big screen spanning all
   the monitors. We can change this to display same screen in all the
   monitors by =mirroring=.

** Data and time settings
   Linux always uses UTC (Coordinated Universal Time) for its internal
   time settings.

** Network time protocol (NTP)
   NTP is the most popular and reliable protocol for setting local
   time from internet servers. Linux can set the system's local time
   by referring to specific time servers run by distribution.

** Network Configuration
   All Linux distributions have configuration files for managing
   network. File formats and locations can differ from one
   distribution to another. Hand editing these files can handle
   complicated setup. For simple configuration *Network Manager* tool
   was designed. It can lists all available networks (both wired and
   wireless), allow the choice of a wired, wireless or mobile
   broadband network, handle passwords and set vpn. Network manager
   establishes the connections and keep track of our settings.

   The hardware interface and presence of signal is automatically
   detected and then network manager sets the actual network settings
   via *DHCP*. Static configuration can also be done via network
   manager.

   Network manager can manage vpn connections also. It supports many
   VPN technologies such as IPSec.
  
* Linux Documentation Sources
** Man pages
   man stands for manual pages. man program searches, formats and
   displays the information contained in the man pages. Many topics
   have a lot of information, output is piped through a terminal pager
   (less) program such as less to be viewed one page at a time.

   man pages provide in-depth documentation about programs and other
   topics about the system including configuration files, system
   calls, library routines, and the kernel.

   man pages are organized together in the form of 9 chapters. The
   chapter number can be used to force man to display the page from a
   particular chapter.

   - man -f :: searches for man pages containing a string in
               them. generates the result as typing *whatis*
   - man -k :: view all man pages that discuss a specified
               subject. generates the same result as typing *apropos*
   - man -a :: man will display all pages with the given name in all
               chapters, one after the other.

** gnu info
   we can use =info <topic-name>= to information about the topic.

** help
   =topic -h= or =topic --help= are used for quick reference.  =help=
   display a short synopsis of built-in shell commands.

** Desktop help
   we can start the desktop help system from a graphical terminal
   using the =gnome-help= command.

** Package documentation
   This documentation is directly pulled from the upstream source
   code.  It can also contain information about how the distribution
   is packaged and set up the software. Such information is placed
   under the =/usr/share/doc= directory in a subdirectory named after
   the package, perhaps including the version number in the name.

** Online resources
   - https://www.centos.org/docs/ (centos documentation)
   - http://linuxcommand.org/tlcl.php (Linux command help)

* Command line operations
** X Windows system
   The customizable nature of Linux allows us to drop (temporarily or
   permanently) the X windows graphical interface, or to start it up
   after the system has been running.

   Linux production servers are usually installed without X and even
   if it is installed, usually do not launch it during start
   up. Removing X from a production server can be very helpful in
   maintaining a lean system which can be easier to support and keep
   secure.

** Virtual Terminals
   Virtual terminals are console sessions that use entire display and
   keyboard outside of a graphical environment. Such terminals are
   considered "virtual" because it is not same as command line
   terminal window. Although we can have multiple active terminals,
   only one terminal remains visible at a time.

   Example situation where virtual terminal can be used is when we
   face problem with graphical interface, then we can switch to one of
   the virtual terminal and troubleshoot the problem.

   To switch between the VTs, press *ctrl-alt-corresponding function
   key* for the VT. Example: we will have to press *ctrl-alt-F6* for
   VT 6. We only have to press *alt-F6* if we are in already in a VT
   not running X and want to switch to another VT.

** Command line
   There are three basic elements of a command line:
   - command :: actual command
   - options :: switch to the commands
   - arguments :: input over which command operates on

** Turn off graphical desktop
   In debian based system desktop manager runs as a service. We can
   stop the service at anytime. For rpm-based system the desktop
   manager is run directly by init when set to run level 5; switching
   to a different runlevel stops the desktop.

   1. In debian based system
      #+BEGIN_EXAMPLE
      sudo service lightdm stop
      sudo service gdm stop
      #+END_EXAMPLE

   2. In RPM based system
      #+BEGIN_EXAMPLE
      sudo telinit 3
      #+END_EXAMPLE

** Schedule shutdown
   Schedule system's shutdown and inform all the users logedin to the
   system.
   #+BEGIN_EXAMPLE
   shutdown -h 10:00 "Shutting down for scheduled maintenance"
   #+END_EXAMPLE

** Locating applications
   1. One way is to use which, it searches only for executables.
      #+BEGIN_EXAMPLE
      $ which apt-get 
      /usr/bin/apt-get
      #+END_EXAMPLE
   2. Another way is to use whereis. It looks for the packages in a
      broader range of system directories.
      #+BEGIN_EXAMPLE
      $ whereis apt-get
      apt-get: /usr/bin/apt-get /usr/bin/X11/apt-get /usr/share/man/man8/apt-get.8.gz
      #+END_EXAMPLE

** Stat
   Status of the file can be found using =stat= command. Links values
   shows the number of hard links the file have including itself.
   #+BEGIN_EXAMPLE
   yogesh@machine:~/projects/documents$ stat linux-foundation-course.org 
   File: 'linux-foundation-course.org'
   Size: 14462     	Blocks: 32         IO Block: 4096   regular file
   Device: 807h/2055d	Inode: 4071531     Links: 1
   Access: (0664/-rw-rw-r--)  Uid: ( 1000/  yogesh)   Gid: ( 1000/  yogesh)
   Access: 2016-04-03 10:33:40.382986825 +0530
   Modify: 2016-04-03 10:00:57.074984368 +0530
   Change: 2016-04-03 10:36:33.314987042 +0530
   Birth: -
   #+END_EXAMPLE

** Hard and Soft links
   Following diagram best illustrates the difference between a hard
   link and a soft link.
   
   [[./diagrams/hard-and-soft-link.jpg]]

*** Soft link
    Soft link is a new file which only contains the name of the
    original file. It has different inode number than the original
    file. Symlinks works across the filesystem. If the original file
    is deleted the symlink will no longer be valid, however the file
    will continue to exist.
    #+BEGIN_EXAMPLE
    ln -s original-file symlink
    #+END_EXAMPLE

*** Hard link
    Hard link is a new file which points to the same inode number as
    the original file. If original file is deleted the hard link will
    still exist. When either of the hard link or original file is
    modified the changes are reflected in both of the files. If we
    delete the original file, the hard link will still exist. The
    inode will only be deleted when all the links to it are
    deleted. Hard link does not work across the filesytem. The hard
    link and the original file has to be in the same filesystem. To
    create a hard link use following command:
    #+BEGIN_EXAMPLE
    ln original-file hardlink
    #+END_EXAMPLE

** File streams
   When a command is run, three file descriptors are open by default
   one for reading standard input (*stdin*), one for writing standard
   output (*std out*) and one for writing standard error (*std
   err*). These files are accessed via file descriptors.

   In Linux all open files are represented by file descriptors. File
   descriptors are number starting with 0 for stdin, 1 for stdout and
   2 for stderr. If any other descriptors are open in addition to
   these default descriptors, then there numbering will start after 3.

   stdin is usually keyboard, stdout and stederr are terminal by
   default. These descriptors can be changed as per the
   requirements. For example we can make command to take input from a
   file and write to a file instead of keyboard using redirection. We
   can also send output of one command to be as the input for another
   command using pipe.

** I/O redirection
   In shell we can redirect the standard file stream so that we can
   get input from a file, or from keyboard. We can redirect standard
   output and standard error to a file, or terminal or to command.

   To redirect use file descriptor number, for example to redirect
   stderr use:
   #+BEGIN_EXAMPLE
   some_program 2> errorout
   some_program > outfile
   #+END_EXAMPLE

** Pipe
   Many small programs cooperate together to accomplish some complex
   task. This is done by using =pipes=.
   #+BEGIN_EXAMPLE
   prog1 | prog2 | prog3
   #+END_EXAMPLE

   This is very efficient as prog2 and prog3 does not have to wait for
   the previous pipe programs to complete before they begin hacking at
   the data in their input streams. In addition to this there is no
   need to save output in a temporary file between the stages in
   pipeline. Which saves disk space and improves efficiency as disk
   I/O is often slowest bottleneck in getting something done.

** Wildcards and matching file name
   |-----------+-----------------------------------|
   | Wildcards | Result                            |
   |-----------+-----------------------------------|
   | ?         | Matches any single character      |
   |-----------+-----------------------------------|
   | *         | Matches any string of characters  |
   |-----------+-----------------------------------|
   | [set]     | Matches any characters in the set |
   |           | of characters                     |
   |-----------+-----------------------------------|

   To search for files using =?= wildcard, replace each unknown
   character with ?, e.g. if we know only the first 2 letters are 'ba'
   of a 3-letter filename with an extension of .out, type:
   #+BEGIN_EXAMPLE
   ls ba?.out
   #+END_EXAMPLE
  
   To search for files using the =*= wildcard, replace the unknown
   string with *, e.g. If we remember only that the extension was
   .out, type:
   #+BEGIN_EXAMPLE
   ls *.out
   #+END_EXAMPLE

** locate
   locate command perform search through a previously constructed
   database of files and directories on our system, matching all
   entries that contain a specified character string. This can
   sometimes result in a very long list.

   To get a shorter more relevant list we can use the grep program as
   filter; grep will print only lines that contain one or more
   specified strings as in:
   #+BEGIN_EXAMPLE
   $ locate zip | grep bin
   #+END_EXAMPLE


   locate utilizes database created by another program called
   =updatedb=. Linux does update automatically once in a day, but the
   database can be updated manually using the =updatedb=.

   Following example command will print absolute path of all the files
   and directories matching the give name.
   #+BEGIN_EXAMPLE
   locate test
   #+END_EXAMPLE

** find
   find command recurses down the file system tree from the specified
   directory and searches for file matching given conditions. The
   default directory is present directory.
   #+BEGIN_EXAMPLE
   find /usr -type d -iname directory_name
   find /usr -type f -iname file_name
   find /usr -type l -iname link_name
   #+END_EXAMPLE
   
   find command has very useful options used for administration.  With
   these options number can be expressed either as =n= that means
   exactly that value, =+n= which means greater than that number, or
   =-n= which means lesser than the number.

   1. To find files based on their size, =-size= option is used
      #+BEGIN_EXAMPLE
      find / -size +10M
      find / -size 0
      #+END_EXAMPLE

   2. To find files and execute some command on them, =-exec= option
      is used.
      #+BEGIN_EXAMPLE
      find / -size +10M -exec rm {} \;
      #+END_EXAMPLE
      Where 'rm' is the command to run, '{}' is the placeholder which
      will be replaced with files and ';' is used to indicate end.

   3. To find files based on time:
      + =-ctime= for searching based on created time
      + =-atime= for searching based on accessed/read time
      + =-mtime= for searching based on modified/write time
     
      The number is the number of days.
      #+BEGIN_EXAMPLE
      find / -ctime 1
      #+END_EXAMPLE
    
      There are similar options for times in minutes (as in =-cmin=,
      =-amin= and =-mmin=)
    
** Working with files
   Following commands can be used to view files.
|---------+--------------------------------------------------------------------------------|
| command | usage                                                                          |
|---------+--------------------------------------------------------------------------------|
| cat     | Used for viewing files that are not very long; it does provide any scroll-back |
|---------+--------------------------------------------------------------------------------|
| tac     | Used to look files backwards;                                                  |
|---------+--------------------------------------------------------------------------------|
| less    | Used to view larger files because it is a paging program; it pauses at each    |
|         | screenful of text, provides scroll-back capabilities, and lets us search and   |
|         | navigate within the file.                                                      |
|---------+--------------------------------------------------------------------------------|
| tail    | Used to print the last 10 lines of a file by default. The number of lines can  |
|         | be changed by doing -n 15 or just -15                                          |
|---------+--------------------------------------------------------------------------------|
| head    | The opposite of tail                                                           |
|---------+--------------------------------------------------------------------------------|
 
** touch
   touch is used to set or update access, change and modify times of
   files. By default it resets a file's time stamp to match the
   current time.

   touch command can also be used to create empty files. This is
   normally done to create empty files as a placefolder for a later
   purpose.

   To set timestamp of a file use =touch= command with =-t= option.
   #+BEGIN_EXAMPLE
   touch -t 03201600 file
   #+END_EXAMPLE

** mkdir
   mkdir command is used to create a directory.
   #+BEGIN_EXAMPLE
   mkdir test
   mkdir test/test2
   #+END_EXAMPLE

** command line prompt
   The PS1 variable is the character string that is displayed as the
   prompt on the command line.
   #+BEGIN_EXAMPLE
   yogesh@machine:~/projects/documents$ echo $PS1
   \[\e]0;\u@\h: \w\a\]${debian_chroot:+($debian_chroot)}\u@\h:\w\$
   #+END_EXAMPLE

* Package management
  Package management systems provide two tool levels; a low-level tool
  (such as dpkg or rpm), takes care of the unpacking of individual
  packages, running scripts, getting the software installed correctly,
  while a high level tool (such as apt-get or yum) works with groups
  of packages, downloads packages from the vendor, and figures out
  dependencies.

  Dependency tracking is a particularly important feature of the
  high-level tool as it handles the details of finding and installing
  each dependency. Installing a single packages could result in many
  dozens or even hundreds of dependent packages being installed.

** apt
   The advanced packaging tool (apt) is the package management system
   that manages software on Debian-based systems. It forms the backend
   for graphical package managers, such as the Ubuntu Software Center
   and synaptic. Its native user interface at the command line, with
   programs that include =apt-get= and =apt-cache=.

   Following table presents some basic commands used for debian and
   fedora family system.

   |--------------------------------+--------------------+------------------------|
   | *Operation                     | RPM                | deb*                   |
   |--------------------------------+--------------------+------------------------|
   | Install package                | rpm -i foo.rpm     | dpkg --install foo.deb |
   |--------------------------------+--------------------+------------------------|
   | Install package, dependencies  | yum install foo    | apt-get install foo    |
   |--------------------------------+--------------------+------------------------|
   | Remove package                 | rpm -e foo.rpm     | dpkg --remove foo.deb  |
   |--------------------------------+--------------------+------------------------|
   | Remove package, dependencies   | yum remove foo     | apt-get remove foo     |
   |--------------------------------+--------------------+------------------------|
   | Update package                 | rpm -U foo.rpm     | dpkg --install foo.deb |
   |--------------------------------+--------------------+------------------------|
   | Update package, dependencies   | yum update foo     | apt-get install foo    |
   |--------------------------------+--------------------+------------------------|
   | Update entire system           | yum update         | apt-get dist-upgrade   |
   |--------------------------------+--------------------+------------------------|
   | Show all installed packages    | rpm -qa or         | dpkg --list            |
   |                                | yum list installed |                        |
   |--------------------------------+--------------------+------------------------|
   | Get information on package     | rpm -qil foo       | dpkg --listfiles foo   |
   |--------------------------------+--------------------+------------------------|
   | Show packages named foo        | yum list "foo"     | apt-cache search foo   |
   |--------------------------------+--------------------+------------------------|
   | Show all available packages    | yum list           | apt-cache dumpavail    |
   |--------------------------------+--------------------+------------------------|
   | What packages is file part of? | rpm -qf file       | dpkg --search file     |
   |--------------------------------+--------------------+------------------------|
   | List packages matching given   |                    | dpkg -l <package-name> |
   | pattern                        |                    |                        |
   |--------------------------------+--------------------+------------------------|

*** remove
    It is used to remove packages. Removing a package leaves its
    configuration files on the system.
*** purge
    It is identical to remove, except that the packages are removed
    and purged (any configuration files are deleted too).
*** autoremove
    It is used to remove packages that were automatically installed to
    satisfy dependencies of other packages and are now no longer needed.

* File Systems
** Partitions in linux
   Each filesytem resides on a hard disk partition. Partitions help
   organize the contents of disks according to the kind of data
   contained and how it is used. For example important programs
   required to run the system are often kept on a separate partition
   (known as root or /) than the one that contains files owned by
   regular users of that system (/home). Temporary files created and
   destroyed during normal linux operations are kept on a separate
   partition (/tmp).

** Mount points
   Filesystem are usable only after they are mounted on some
   directory. Filesystem are often mounted on empty directory. If
   mounted on nonempty directory the former contents is covered up and
   not accessible until the filesystem is unmounted. Thus filesystems
   are mounted on empty directory.

   The =mount= command is used to attach a filesystem (which can be
   local to computer or on a network) somewhere within the filesystem
   tree. Arguments include the =device node= and =mount point=. For
   example following command will attach the filesystem contained in
   the disk partition associated with the =/dev/sda5= device node,
   into the filesystem tree at the =/home= mount point.
   #+BEGIN_EXAMPLE
   $ mount /dev/sda5 /home
   #+END_EXAMPLE

   To make the partition, mount automatically at the time of startup,
   we need to edit the =/etc/fstab= file. Looking at this file will
   show us the configuration of all pre-configured filesystems.

   The command =df -Th= will display information about the mounted
   filesystems including usage statistics.
   #+BEGIN_EXAMPLE
   $ df -Th
   Filesystem     Type      Size  Used Avail Use% Mounted on
   udev           devtmpfs  1.9G  4.0K  1.9G   1% /dev
   tmpfs          tmpfs     385M  1.3M  383M   1% /run
   /dev/sda5      ext4       20G  7.5G   12G  41% /
   none           tmpfs     4.0K     0  4.0K   0% /sys/fs/cgroup
   none           tmpfs     5.0M     0  5.0M   0% /run/lock
   none           tmpfs     1.9G  328K  1.9G   1% /run/shm
   none           tmpfs     100M   60K  100M   1% /run/user
   /dev/sda7      ext4      100G   62G   33G  66% /home
   #+END_EXAMPLE
  
** fstab
   *fstab* is a configuration file that contains information of all
    the partitions and storage devices in a computer. The file is
    located at =/etc=, so the full path to the file is =/etc/fstab=.

    =/etc/fstab= contains information of where our partitions and
    storage devices should be mounted and how. If we can't access the
    Windows partition from Linux, are not able to mount the CD or
    write to the floppy as a normal user, then the =/etc/fstab= file
    may be misconfigured.
    
    #+BEGIN_EXAMPLE
    UUID=aa823ffc-d42f-45f3-b322-35f582c3e1c4 /               ext4    errors=remount-ro 0       1
    # /home was on /dev/sda7 during installation
    UUID=d38fca95-52a3-4536-8555-c5d345062587 /home           ext4    defaults        0       2
    # swap was on /dev/sda6 during installation
    UUID=e1402b0a-971b-4bc6-a84f-4650d04f77a5 none            swap    sw              0       0
    #+END_EXAMPLE

    The first column contains the device name, the second one its
    mount point, third its file system type, fourth the mount options,
    fifth (a number) dump options, and sixth (another number) file
    system check options.

* Network Filesystem (NFS)
  Network filesystem is one of the methods used for sharing data
  across physical systems. Remote user's home directory can be mounted
  on a server to allow access to the same files and configuration
  files across multiple client systems. This allow users to log in to
  different computers yet still have access to the same files and
  resources.
** NFS on the server
   On the server machine, directories and permissions are defined to
   allow sharing of files over nfs. File =/etc/exports= contains the
   directories and permissions that a host is willing to share with
   other systems over NFS. Below example allows =/projects= directory
   to be remotely mounted with read and write permissions.
   #+BEGIN_EXAMPLE
   /projects *.example.com(rw)
   #+END_EXAMPLE
  
   After modifying the =/etc/exports= file we can notify Linux about
   the change by executing =exportfs -av= command. Restarting NFS with
   =sudo service nfs restart= will also work, but is heavier as it
   halts NFS for a short while before starting it up again.

** NFS on the client
   On the client machine we can mount the remote filesystem by
   following command.
   #+BEGIN_EXAMPLE
   mount servername:/projects /mnt/nfs/projects
   #+END_EXAMPLE
   To automatically mount the remote filesystem make an entry in
   =/etc/fstab= as follows:
   #+BEGIN_EXAMPLE
   servername:/projects /mnt/nfs/projects nfs default 0 0
   #+END_EXAMPLE  
* Proc Filesystem
  The =/proc= filesystem contains virtual files, that exist only in
  memory that permit viewing constantly varying kernel data. This
  filesystem contains files and directories that mimic kernel
  structure and configuration information.

  =/proc= has subdirectories such as:
  1. =/proc/<process-id-#>= : There is a directory for every process
     running on the system which contains vital information about it.

  2. =/proc/sys= : This directory contains a lot of information about
     the entire system.
  
* Filesystem architecture
** /bin and /sbin directories
   The =/bin= directories contains executable binaries, essential
   commands used in single-user mode, and essential commands required
   by all system users. These executable programs are used to bring
   the system up or repair it.
  
   =/sbin= directory contains commands that are essential for system
   administration. These commands are usually not used by normal
   users.

   =/usr/bin= directory contains commands that are not essential for
   the system.

   =/usr/sbin= contains commands that are less essential for system
   administration.

   The reason essential commands were separately placed in =/sbin= is
   because sometimes =/usr= directory may be mounted on a separate
   partition and may not be available/mounted in a single-user mode.

** /dev directory
   =/dev= directory contains files that are used by most hardware and
   software devices, except for network devices. It creates and
   manages device nodes on Linux, creating them dynamically when
   devices are found.
   1. /dev/sda1 (first partition on the first hard disk)
   2. /dev/lp1 (printer)
   3. /dev/dvd1 (DVD drive)

** /var directory
   =var= stands for variable. =/var= directory contains files that are
   expected to change in size and content as the system is running.
   Example files are:
   1. System log files: /var/log
   2. Database and packages: /var/lib
   3. Print queue: /var/spool
   4. Temp files: /var/tmp

   The =/var= directory can be put in its own filesystem so that the
   growth of the files can be accommodated and the file sizes do not
   affect the system.

   Network service directories such as =/var/ftp= (the ftp service)
   and =/var/www= (the http service) are also found under =/var=.

** /etc directory
   =/etc= directory contains system configuration files. For example,
   =/etc/resolv.conf= tells the system where to go for resolving host
   name to ip address. Files like =passwd=, =shadow= and =group= are
   found in the =/etc= directory.

   System run level scripts are found inside subdirectories of
   =/etc=. For example =/etc/rc2.d= contains links to scripts for
   entering and leaving run level 2.

** /boot directory
   =/boot= directory contains files needed to boot the system. For
   every alternative kernel installed on the system there are
   following four corresponding files:
   1. vmlinuz: the compressed Linux kernel, required for booting
   2. initramfs: the initial ram filesystem, required for booting
   3. config: the configuration file, only used for debugging and bookkeeping
   4. system.map: kernel symbol table used for debugging

   The Grand Unified Bootloader (GRUB) files (such as
   =/boot/grub/grub.conf=) are also found under the =/boot= directory.

** /lib and /media directory
   =/lib= directory contains libraries for the essential programs in
   =/bin= and =/sbin=. These library filenames either start with =ld=
   or with =lib=.

   =/media= is typically located where removable media such as CDs,
   DVDs and USB drives are mounted. Linux automatically mounts the
   removable media in the =/media= directory when they are detected.

** Additional directories under /
|----------------+------------------------------------------------------|
| Directory Name | Usage                                                |
|----------------+------------------------------------------------------|
| /opt           | Optional application software packages               |
|----------------+------------------------------------------------------|
| /tmp           | Temporary files; on some distributions erased across |
|                | a reboot and/or may actually be a ramdisk in memory  |
|----------------+------------------------------------------------------|
| /usr/lib       | Libraries for programs in /usr/bin and /usr/sbin     |
|----------------+------------------------------------------------------|
| /usr/src       | Source code usually for the Linux kernel             |
|----------------+------------------------------------------------------|
 
* Comparing files and filetypes
  =diff= command is used to compare files and directories. To compare
  two files use following command.
  #+BEGIN_EXAMPLE
  diff <filename1> <filename2> 
  #+END_EXAMPLE

|-------------+--------------------------------------------|
| diff option | Usage                                      |
|-------------+--------------------------------------------|
| -r          | Used to recursively compare subdirectories |
|             | as well as the current directory           |
|-------------+--------------------------------------------|
| -i          | Ignore the case of letters                 |
|-------------+--------------------------------------------|
| -w          | Ignore differences in spaces and tabs      |
|-------------+--------------------------------------------|

* Backup
  =rsync= utility in Linux provides useful way to take backup of files
  and folders. =rsync= command can be used to copy files to/from local
  machine as well as to/from network machine.

  =rsync= is efficient in a way that it transfers only the differences
  between the files. Whereas =cp= command transfers the complete
  file.

  =rsync= utility can be destructive if not handled with care. It is
  advisable to always do a dry run using =-dry-run= or =-n= option,
  before doing the actual transfer. Dry run is used in conjunction
  with =--verbose= option.
  #+BEGIN_EXAMPLE
  rsync -r -v -n ~/projects ~/Desktop
  #+END_EXAMPLE

* Archive and compression
  Compression is used to save disk space and reduce the time it takes
  to transfer the files over network. In addition tar utility is often
  used to group files in an archive and then compress the whole
  archive at once.

  =tar= stands for tape archive and is used to archive files to a
  magnetic tape.
  1. Creating a tar of all the files and folders in present working
     directory.
     #+BEGIN_EXAMPLE
     tar -cvf my.tar *
     #+END_EXAMPLE

  Files can be saved in the compressed form, for future use. =xz= is
  the most efficient compression (produces smallest files)
  1. Compress all the files in present working directory.
     #+BEGIN_EXAMPLE
     xz *
     #+END_EXAMPLE
  2. Compress the file foo
     #+BEGIN_EXAMPLE
     xz foo
     #+END_EXAMPLE

  Archiving and compression can be done together using =tar=
  1. Create the archive and compress with =xz=
     #+BEGIN_EXAMPLE
     tar -Jcvf mydir.tar.xz mydir
     #+END_EXAMPLE
  2. Create the archive and compress with =gzip=
     #+BEGIN_EXAMPLE
     tar -zcvf mydir.tar.gz mydir
     #+END_EXAMPLE

* Disk to disk copying
  =dd= command is very useful for making copies of raw disk space. To
  make a copy of one disk onto another, deleting everything that
  perviously existed on the second disk, type:
  #+BEGIN_EXAMPLE
  dd if=/dev/sda of=/dev/sdb
  #+END_EXAMPLE
* Basics of users and groups
  Linux uses groups for organizing users. Groups are collection of
  user accounts with certain shared permissions. Control of group
  membership is administered through the =/etc/group= file, which
  shows a list of groups and their members.

  All Linux users are assigned a unique user ID (uid), which is just
  an integer, as well as one or more group ID's (gid), including the
  default one which is the same as the user ID.

  These numbers are associated with the names through the files
  =/etc/passwd= and =/etc/group=.

** Adding and removing users
   Users can be added and deleted only by the root user. Normal user
   can not perform this action. =adduser= command is used to create
   user and =userdel= command is used to delete user.

   To create an user =turkey= execute following command, which will
   sets the home directory to =/home/turkey=, populates with some
   basic files (copied from =/etc/skel=) and adds a line to
   =/etc/passwd= file.
   #+BEGIN_EXAMPLE
   sudo adduser turkey
   #+END_EXAMPLE

   Removing a user is as simple as typing =userdel turkey=. However
   this will leave the =/home/turkey= directory intact. This might be
   useful if this is a temporary inactivation. To remove the home
   directory while removing the account we can use =-r= option with
   =userdel= command.

   To get the current user information use =id= command.
   #+BEGIN_EXAMPLE
   id
   uid=1000(yogesh) gid=1000(yogesh) groups=1000(yogesh),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),108(lpadmin),124(sambashare),999(docker)
   #+END_EXAMPLE
  
** Adding and removing groups
   1. Adding a new group can be done with =addgroup= command
      #+BEGIN_EXAMPLE
      sudo addgroup <groupname>
      #+END_EXAMPLE
   2. The group can be removed with
      #+BEGIN_EXAMPLE
      delgroup <groupname>
      #+END_EXAMPLE
   3. Adding a user to an already existing group is done with
      =usermod= command.
      #+BEGIN_EXAMPLE
      $ groups turkey
      turkey: turkey
      $ usermod -G <newgroup> turkey
      $ groups turkey
      turkey: turkey newgroup
      #+END_EXAMPLE
  
** root account
   The root account is very powerful and has full access to the
   system. Extreme caution must be taken before granting root access
   to a user. *sudo* feature is used to assign more limited privileges
   to user accounts:
   + on only a temporary basis
   + only for a specific subset of commands

** su and sudo
   We can use =su= command to switch to a new user, and launch a new
   shell running as another user. It is almost always a bad (dangerous
   for both security and stability) practise to use =su= to become
   root.

   Granting privileges using =sudo= is less dangerous and is
   preferred. By default, =sudo= must be enabled on a per-user basis.

   =sudo= configuration files are stored in =/etc/sudoers= file and in
   =/etc/sudoers.d= directory.
 
* Startup files
  In Linux, the command shell program (generally *bash*) uses one or
  more startup files to configure the environment. Files in =/etc=
  directory define global settings for all users while initialization
  files in the user's home directory can include and/or override the
  global settings.

  Startup files can do the following:
  1. Customizing the user's prompt
  2. Defining command line aliases and shortcuts
  3. Setting the default text editor
  4. Setting the *path* for where to find executable programs

** Order of the startup files
   On the first login to Linux, =/etc/profile= is read and
   evaluated. After this following files are searched in the listed
   order:
   1. =~/.bash_profile=
   2. =~/.bash_login=
   3. =~/.profile=

   The Linux login shell evaluates whatever startup file that it comes
   across first and ignores the rest.

   When we create a new shell, or terminal window, etc, we do not
   perform a full system login; only the =~/.bashrc= file is read and
   evaluated.

* Environment Variables
  Environment variables are simply named quantities that have specific
  values and are understood by the command shell, such as *bash*. Some
  of these are pre-set (built-in) by the system, and others are set by
  the user either at the command line or within startup and other
  scripts. An environment variable is actually no more than a
  character string that contains information used by one or more
  applications.

  To view values of currently set environment variables we can type
  any of the following command.
  1. set 
  2. env 
  3. export

  Depending on the state of our system, *set* may print out many more
  lines than the other two methods.

** Setting environment variables
   By default, variables created within a script are only available to
   the current shell; child processes (sub-shells) will not have
   access to values that have been set or modified. Allowing child
   processes to see the values requires use of the *export* command.

** PATH Variable
   PATH is an ordered list of directories (the path) which is scanned
   when a command is given to find the appropriate program or script
   to run. Each directory in the path is separated by colons(:). A
   null (empty) directory name (or ./) indicates the current working
   directory at any given time.

   #+BEGIN_EXAMPLE
   :path1:path2 - there is null directory before the first colon
   path1::path2 - there is null directory between path1 and path2
   #+END_EXAMPLE

** PS1 Variable
   *PS1* is the primary prompt variable which controls what our
   command line prompt looks like.

   A better practise would be to save the old prompt first and then
   restore it as in
   #+BEGIN_EXAMPLE
   $ OLD_PS1=$PS1
   #+END_EXAMPLE

** SHELL Variable
   The environment variable shell points to the user's default command
   shell (the program that is handling whatever we type in a command
   window, usually bash) and contains the full pathname to the shell.
* Recalling previous commands
  *bash* keeps track of previously entered commands and statements in
   a history buffer; we can recall previously used commands simply by
   using the up and down cursor keys.

   The list of commands is displayed with the most recent command
   appearing last in the list. The information is stored in
   =~/.bash_history=

** History environment variable
   Several associated environment variable can be used to get
   information about the history file.

   1. HISTFILE stores the information about the history file.
   2. HISTFILESIZE stores the maximum number of lines in the history
      file.
   3. HISTSIZE stores the maximum number of lines in the history file
      for the current session.

* Keyboard shortcuts
|-------------------+---------------------------------------------------|
| Keyboard shortcut | Task                                              |
|-------------------+---------------------------------------------------|
| CTRL-L            | Clears the screen                                 |
|-------------------+---------------------------------------------------|
| CTRL-H            | Works same as backspace                           |
|-------------------+---------------------------------------------------|
| CTRL-U            | Deletes the string from the beginning of the line |
|                   | to the cursor position                            |
|-------------------+---------------------------------------------------|
| CTRL-W            | Deletes the word before the cursor                |
|-------------------+---------------------------------------------------|
| CTRL-Z            | Puts the current process to background in         |
|                   | suspended state                                   |
|-------------------+---------------------------------------------------|
| CTRL-D            | Exits the current shell                           |
|-------------------+---------------------------------------------------|
| CTRL-C            | Kills the current process                         |
|-------------------+---------------------------------------------------|
| CTRL-A            | Goes to the beginning of the line                 |
|-------------------+---------------------------------------------------|
| CTRL-E            | Goes to the end of the line                       |
|-------------------+---------------------------------------------------|
| TAB               | Auto completes files, directories and binaries    |
|-------------------+---------------------------------------------------|

* Aliases
  We can create customized commands or modify the behaviour of already
  existing commands by creating aliases. These aliases are placed in
  =~/.bashrc= file so they are available to any command shells we
  create.

  Typing =alias= with no arguments will list currently defined
  aliases. Alias can be defined temporarily using =alias=
  command. Example
  #+BEGIN_EXAMPLE
  $ alias ls='ls -l'
  #+END_EXAMPLE

  - Note :: There should not be any spaces on either side of the equal
            sign and the alias definition needs to be placed within
            either single quotes or double quotes if it contains any
            spaces.

* File Ownership
  In Linux every file is associated with a user who is the
  *owner*. Every file is also associated with a group (a subset of all
  users) which has an interest in the file and certain rights, or
  permissions: read, write and execute.

|----------+-------------------------------------|
| *Command | Usage*                              |
|----------+-------------------------------------|
| chown    | Used to change the file ownership   |
|----------+-------------------------------------|
| chgrp    | Used to change the group ownership  |
|----------+-------------------------------------|
| chmod    | Used to modify the file permissions |
|----------+-------------------------------------|

  #+BEGIN_EXAMPLE
  chmod uo+x,g-w test1
  chmod 755 test1
  #+END_EXAMPLE
  
  1. read is 4
  2. write is 2
  3. execute is 1

* Text Editors
  Files can be created without using text editors. There are two
  standard way to create files
  1. echo
     #+BEGIN_EXAMPLE
     echo "File content" > test
     echo "More file content" >> test
     #+END_EXAMPLE
  2. cat
     #+BEGIN_EXAMPLE
     cat << EOF > test
     This text is written inside file
     EOF
     #+END_EXAMPLE

** vi
*** Modes in vi
|---------+---------------------------------------------------------|
| *Mode   | Feature*                                                |
|---------+---------------------------------------------------------|
| Command | - By default vi starts in command mode.                 |
|         | - Each key is an editor command.                        |
|         | - Keyboard strokes are interpreted as commands that can |
|         | modify file contents.                                   |
|---------+---------------------------------------------------------|
| Insert  | - Type 'i' to switch to insert mode from command mode   |
|         | - Insert mode is used to insert text into a file        |
|         | - Insert mode is indicated by the text "-- INSERT --"   |
|         | at the bottom of the screen                             |
|         | - Press Esc to exit insert mode and return to command   |
|         |   mode                                                  |
|---------+---------------------------------------------------------|
| Line    | - Type ":" to switch to line mode from command mode.    |
|---------+---------------------------------------------------------|

*** Working with files in vi
|------------+------------------------------------------------|
| *Command   | Usage*                                         |
|------------+------------------------------------------------|
| vi file    | start vi editor and edit file                  |
|------------+------------------------------------------------|
| vi -r file | start vi editor and edit file in recovery mode |
|            | from system crash                              |
|------------+------------------------------------------------|
| :w         | save content to file                           |
|------------+------------------------------------------------|
| :w file    | write the content to file                      |
|------------+------------------------------------------------|
| :r file    | Read in file and insert at current position    |
|------------+------------------------------------------------|
| :x or :wq  | save the content to file and exit              |
|------------+------------------------------------------------|
| :q         | quit                                           |
|------------+------------------------------------------------|
| :q!        | quit even if there are unsaved modifications   |
|            | to the file                                    |
|------------+------------------------------------------------|
| vi file -R | open file in read mode                         |
|------------+------------------------------------------------|
| :e file    | start editing file                             |
|------------+------------------------------------------------|

*** vi commands
|-----------------------+----------------------------------------------------|
| *Command              | Usage*                                             |
|-----------------------+----------------------------------------------------|
| CTRL-G                | Show location in the file and the file status      |
|-----------------------+----------------------------------------------------|
| G                     | move to the bottom of the file                     |
|-----------------------+----------------------------------------------------|
| gg                    | move to the start of the file                      |
|-----------------------+----------------------------------------------------|
| CTRL-o                | go back to where we came from                      |
|-----------------------+----------------------------------------------------|
| Search command - /    | search for the phrase                              |
|-----------------------+----------------------------------------------------|
| Match parentheses - % | find matching ), ], or }                           |
|-----------------------+----------------------------------------------------|
| R                     | To start replace mode                              |
|-----------------------+----------------------------------------------------|
| CTRL-D                | Show list of commands start with entered character |
|-----------------------+----------------------------------------------------|
| CTRL-W                | Jump to another windows                            |
|-----------------------+----------------------------------------------------|
| x                     | delete character at current position               |
|-----------------------+----------------------------------------------------|

*** vi operators
    1. To delete the text use =d=
    2. To replace the text use =r=
    3. To change the text use =c=
    4. To copy the text use =y=

*** Substitute command
    1. To substitute new for the first old in a line type:
       =:s/old/new=.
    2. To substitute new for all occurrences of old in the line type
       =:s/old/new/g=.
    3. To substitute new for all occurrences of old in the whole file
       type: =:%s/old/new/g=.
    4. To substitute new for all occurrences of old in the whole file
       with confirmation type: =:%s/old/new/gc=.
      
*** External command
    Type =:!= followed by an external command to execute that command.
    #+BEGIN_EXAMPLE
    :!ls
    :!rm test
    :! wc %
    :%!fmt
    #+END_EXAMPLE
    Here =%= represents the file currently being edited.

*** Selecting text to write
    To highlight the text type =v= and then move the cursor to select
    the text. Once the text is highlighted we can save the text into a
    file by typing =:= and then =w test=.

*** set option
    1. set 'ic' (Ignore case) option by entering =:set ic=.
    2. set 'is' ('incsearch') option to show partial matches for a
       search phrase.
    2. set the 'hlsearch' option to highlight all matching phrase.
    3. To disable ignoring case enter: =:set noic=.
    4. To remove the highlighting of matches enter: =:nohlsearch=.

** Emacs
   Following table represents common key combination used while
   editing files in emacs.
   |---------------+-----------------------------------|
   | *key          | Usage*                            |
   |---------------+-----------------------------------|
   | emacs myfile  | Start emacs and edit file         |
   |---------------+-----------------------------------|
   | CTRL-x i      | insert prompted for file          |
   |               | at current position               |
   |---------------+-----------------------------------|
   | CTRL-x s      | save all files                    |
   |---------------+-----------------------------------|
   | CTRL-x CTRL-w | write to the file giving new      |
   |               | name when prompted                |
   |---------------+-----------------------------------|
   | CTRL-x CTRL-s | saves the current file            |
   |---------------+-----------------------------------|
   | CTRL-x CTRL-c | exit after being prompted to save |
   |               | any modified files                |
   |---------------+-----------------------------------|

*** Searching for text in emacs
    The table lists the key combinations that are used for searching
    for text in emacs.
    |--------+---------------------------------------|
    | *Key   | Usage*                                |
    |--------+---------------------------------------|
    | CTRL-s | Search forward for prompted pattern   |
    |--------+---------------------------------------|
    | CTRL-r | Search backwards for prompted pattern |
    |--------+---------------------------------------|

*** Working with text in emacs
    The table lists the key combination used for changing, adding and
    deleting text in emacs.
    |--------------+---------------------------------------------|
    | *Key         | Usage*                                      |
    |--------------+---------------------------------------------|
    | CTRL-k       | delete rest of the current line             |
    |--------------+---------------------------------------------|
    | CTRL-(space) | mark the beginning of the selected region   |
    |--------------+---------------------------------------------|
    | CTRL-w       | delete the current marked text and write it |
    |              | to the buffer                               |
    |--------------+---------------------------------------------|
    | CTRL-y       | insert at current cursor location whatever  |
    |              | was most recently deleted                   |
    |--------------+---------------------------------------------|

* Security Principles
** User accounts
   Linux kernel allows authenticated users to access files and
   applications. While each user is identified by a unique integer
   (the user id or UID), a separate database associates a username
   with each UID. Upon account creation, new user information is added
   to the user database and the user's home directory must be created
   and populated with some essential files.

   For each user following seven fields are maintained in the
   =/etc/passwd= file.

|----------------+---------------------------------------------+------------------------------------------------|
| *Field Name    | Details                                     | Remarks*                                       |
|----------------+---------------------------------------------+------------------------------------------------|
| Username       | User login name                             | Should be in beetween 1 and 32 characters long |
|----------------+---------------------------------------------+------------------------------------------------|
| Password       | User password (or the character x           | Is never shown while typing                    |
|                | if the password is stored in /etc/shadow    |                                                |
|                | file) in encrypted format.                  |                                                |
|----------------+---------------------------------------------+------------------------------------------------|
| User ID (UID)  | Every user must have a user id (UID)        | - UID 0 is reserved for root user              |
|                |                                             | - UID's ranging from 1-99 are reserved for     |
|                |                                             | other predefined accounts                      |
|                |                                             | - UID's ranging from 100-999 are reserved for  |
|                |                                             | systems accounts and groups                    |
|                |                                             | - Normal user have UID's of 1000 or greater    |
|----------------+---------------------------------------------+------------------------------------------------|
| Group ID (GID) | The primary Group ID (GID); Group           |                                                |
|                | identification number stored in the         |                                                |
|                | /etc/group file                             |                                                |
|----------------+---------------------------------------------+------------------------------------------------|
| User Info      | This field is optional and allows insertion |                                                |
|                | of extra information about the user such as |                                                |
|                | their name                                  |                                                |
|----------------+---------------------------------------------+------------------------------------------------|
| Home Directory | The absolute path location of user's home   |                                                |
|                | directory                                   |                                                |
|----------------+---------------------------------------------+------------------------------------------------|
| Shell          | The absolute location of a user's default   |                                                |
|                | shell                                       |                                                |
|----------------+---------------------------------------------+------------------------------------------------|

   Example entry of /etc/passwd file:

   #+BEGIN_EXAMPLE
   daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
   #+END_EXAMPLE

** Types of accounts
   Linux has four types of accounts:
   1. root
   2. System
   3. Normal
   4. Network
    
   For a safe working environment, it is advised to grant the minimum
   privileges possible and necessary to accounts, and remove inactive
   accounts. The *last* command, which shows the last time each user
   logged into the system, can be used to help identify potentially
   inactive accounts which are candidates for system removal. 

   Last searches back through the file /var/log/wtmp and displays list
   of all users logged in (and out) since that file was created. A
   pseudo user logs in each time the system is rebooted.  The last
   reboot command will show a log of all reboots since the log file
   was created.

   *lastb* is the same as *last*, except that by default it shows a
   log of the file =/var/log/btmp=, which contains all the bad login
   attempts.

   The practices we use on multi-user business systems are more strict
   than practices we can use on personal desktop systems that only
   affect the casual user. This is especially true with security.

** root account
   =root= is the most privileged account in Linux system.  This
   account has the ability to carry out all facets of system
   administration, including root accounts, changing passwords,
   examining log files, installing software, etc.  It has no security
   restrictions imposed upon it.

** Operations that require root privileges
   =root= privileges are required to perform operations such as:
   1. creating, removing and managing user accounts.
   2. managing software packages.
   3. removing or modifying system files.
   4. restarting system services.

   =root= privilege is required for performing administration tasks
   such as restarting services and managing parts of the filesystem
   that are outside the normal user's directories.

** Operations that do not require root privileges - SUID
   A regular account user can perform some operations requiring
   special permissions.

   SUID (Set owner User ID upon execution) - is a special kind of file
   permission given to a file. SUID provides temporary permissions to
   a user to run a program with the permissions of file *owner* (which
   may be root) instead of permissions held by the user.

   Examples of files, with suid set:

   1. chmod the user permissions:
      #+BEGIN_EXAMPLE
      -rwsr-xr-x 1 root root 47032 Jan 27 06:20 /usr/bin/passwd
      #+END_EXAMPLE

   2. chmod the group permissions: it runs as someone in the group.
      #+BEGIN_EXAMPLE
      -rwxr-sr-x 1 root shadow 55000 Jan 27 06:20 /usr/bin/chage
      #+END_EXAMPLE
 
   - refer: http://www.linuxnix.com/suid-set-suid-linuxunix/

   - Example1: passwd command ::
        When we try to change password of a user, using passwd command
        which is owned by the root. This =passwd= command will try to
        edit some system config files such as =/etc/passwd= and
        =/etc/shadow= etc when we try to change our password. Some of
        these files can not be viewed/edited by the normal user, only
        root user will have permissions. So if we try to remove SUID
        and give full permissions to this passwd command file it
        cannot open other files such as /etc/shadow file to update the
        changes and we will get permission denied error or some other
        error when tried to execute password command. So passwd
        command is set with SUID to give root user permissions to
        normal user so that it can update /etc/shadow and other files.

   - Example2: ping command ::
	When we execute ping command, it creates sockets internally
        and open ports to send and receive IP packets. Normal user
        don't have permissions to create sockets and open ports, root
        privileges is required to perform this tasks. Hence SUID bit
        is set in ping command/file so that whoever executes this
        command will get owner (root) permissions to open socket files
        and ports.

*** How to set SUID for a file
    1. Symbolic way
       #+BEGIN_EXAMPLE
       u+s file.txt
       #+END_EXAMPLE

    2. Numerical way
       #+BEGIN_EXAMPLE
       chmod 4750 file.txt
       #+END_EXAMPLE

*** Find all the SUID set files
    #+BEGIN_EXAMPLE
    find / -perm +4000
    #+END_EXAMPLE

** sudo vs su
   In Linux we can use either =su= or =sudo= to temporarily grant root
   access to a normal user.

   |--------------------------------------------+---------------------------------------------|
   | *su                                        | sudo*                                       |
   |--------------------------------------------+---------------------------------------------|
   | While elevating privileges root's password | While elevating privileges user's password  |
   | is required. Giving the root password      | is required not the root password           |
   | to a normal user should never ever be done |                                             |
   |--------------------------------------------+---------------------------------------------|
   | Once entered using su, a user can perform  | sudo provides various configurable features |
   | all the tasks of root user, for as long as | to control and limit access. User has to    |
   | the user wants without being asked again   | every time provide password while executing |
   | for the password.                          | command or the password will be saved for   |
   |                                            | the configurable interval.                  |
   |--------------------------------------------+---------------------------------------------|
   | It has limited logging features.           | Actions details are logged in a log file.   |
   |                                            | sudo commands and failures are logged in    |
   |                                            | /var/log/auth.log under the Debian system   |
   |                                            | and /var/log/messages in other distribution |
   |                                            | system.                                     |
   |--------------------------------------------+---------------------------------------------|
  
** Sudoers file
   Whenever sudo is invoked, a trigger will look at =/etc/sudoers= and
   the files in =/etc/sudoers.d= to determine if the user has the
   right to use sudo and what the scope of their privilege is.

   It is preferred to add a file in the directory =/etc/sudoers.d=
   with a name the same as the user. This file contains the individual
   user's sudo configuration, and one should leave the master
   configuration untouched except for changes that affect all users.

   The basic structure of an entry is:
   #+BEGIN_EXAMPLE
   who where = (as_whom) what
   #+END_EXAMPLE

   sudoers file must be edited carefully. We can edit the sudoers file
   using =visudo= command. If there are any mistakes in the file, then
   we will not be able to execute the sudo command. The best way to
   edit sudoers file is to use =visudo= command, for example:
   #+BEGIN_EXAMPLE
   sudo visudo -f /etc/sudoers.d/user1
   #+END_EXAMPLE
   This ensures that only one person is editing the file at a time,
   has the proper permissions, refuses to write out the file and exit
   if there is an error in the changes made.

   If there are any syntax errors in the sudoers file then we will not
   be able to execute root privileged command. Then we have to use
   =pkexec= command as follows to correct the error.

   #+BEGIN_EXAMPLE
   pkexec visudo -f /etc/sudoers.d/filename
   #+END_EXAMPLE

   =pkexec= is a similar command to =sudo=. It allows user to execute
   a command as another user.

   Refer the below link to understand better:
   http://askubuntu.com/questions/73864/how-to-modify-a-invalid-etc-sudoers-file-it-throws-out-an-error-and-not-allowi

** command logging
   *sudo* commands are logged in =/var/log/auth.log= under the Debian
   distribution, and in =/var/log/secure= or =/var/log/messages= on
   other systems.

   A typical entry of the message contains:
   - calling username
   - terminal info
   - working directory
   - user account invoked
   - command with arguments

   Running a command such as sudo results in a log file entry such as:
   #+BEGIN_EXAMPLE
   1 May 23 08:06:17 machine sudo:   yogesh : TTY=pts/11 ; PWD=/home/yogesh/work/projects/documents/linux ; USER=root ; COMMAND=/usr/bin/whoami
   #+END_EXAMPLE 

** Process Isolation
   Linux is considered to be more secure than many other operating
   systems, because processes are naturally isolated from each
   other. One process normally can not access the resources of another
   process, even when that process is running with the same user
   privileges. Linux thus makes it difficult for viruses and security
   exploits to access and attack random resources on a system.

** Security mechanism
   Additional security features that have been recently introduced in
   order to make risks even smaller are:

*** Control Groups (cgroups):
    Allow system administrators to group processes and associate
    finite resources to each cgroup.

*** Linux Containers (LXC):
    Makes it possible to run multiple Linux systems (containers) on a
    single system by relying on *cgroups*.

*** Virtualization
    Hardware is emulated in such a way that not only processes can be
    isolated, but entire systems are run simultaneously as isolated
    and insulated guests (virtual machine) on one physical host.
   
** Hardware Device Access
   Linux limits user access to non-networking hardware devices in a
   manner that is extremely similar to regular file
   access. Applications interact by engaging the filesystem
   layer. This layer will then opens a *device special file* under the
   */dev* directory that corresponds to the device being
   accessed. Each device special file has standard owner, group and
   world permission fields. Security is naturally enforced just as it
   is when standard files are accessed.

   Hard disks, for example, are represented as /dev/sd*. While a root
   user can read and write to disk in a raw fashion
   #+BEGIN_EXAMPLE
   $ echo hello world > /dev/sda1
   #+END_EXAMPLE

   #+BEGIN_EXAMPLE
   $ ls -l /dev/sda
   brw-rw---- 1 root disk 8, 0 May 24 07:09 /dev/sda
   #+END_EXAMPLE

   the standard permissions as shown above make it impossible for
   regular users to do so. Writing to a device in this fashion can
   easily obliterate the filesystem stored on it in a way that cannot
   be repaired without great effort, if at all.

** Update System
   When security problems in either the Linux kernel or applications
   and libraries are discovered, Linux distributions have a good
   record of reacting quickly and pushing out fixes to all systems by
   updating their software repositories and sending notifications to
   update immediately. The same thing is true with bug fixes and
   performance improvements that are not security related.

   Many of the most successful attack vectors come from exploiting
   security holes for which fixes are already known but not
   universally deployed.

   So the best practise is to take advantage of our Linux
   distribution's mechanism for automatic updates and never postpone
   them. It is extremely rare that such an update will cause new
   problems.

** Passwords
   The system verifies authenticity and identifies, using user
   credentials. Originally, encrypted passwords were stored in the
   =/etc/passwd= file, which was readable by everyone. This made it
   rather easier for passwords, to be cracked. On modern systems,
   passwords are actually stored in an encrypted format in a secondary
   file named =/etc/shadow=. Only those with root access can
   modify/read this file.

** Password Encryption
   Linux distributions rely on a modern password encryption algorithm
   called *SHA-512* (Secure Hashing Algorithm 512 bits). The SHA-12
   algorithm is widely used for security applications and
   protocols. These security applications and protocols include TLS,
   SSL, PHP, SSH, S/MIME and IPSec. *SHA-512* is one of the most
   tested hashing algorithms.
  
   Example:
   #+BEGIN_EXAMPLE
   $ echo -n test | sha512sum 
   0e3e75234abc68f4378a86b3f4b32a198ba301845b0cd6e50106e874345700cc6663a86c1ea125dc5e92be17c98f9a0f85ca9d5f595db2012f7cc3571945c123  -
   #+END_EXAMPLE

** Good Password Practices
*** Password aging
    It is a method to ensure that users get prompts that remind them
    to create a new password after a specific period. This can ensure
    that passwords, if cracked, will only be usable for a limited
    amount of time. This feature is implemented using *chage*, which
    configures the password expiry information for a user.
  
    Executing *chage* command requires root privileges because the
    command edits the user information in =/etc/shadow= file which is
    owned by the root. =/etc/shadow= file has following permissions:
    #+BEGIN_EXAMPLE
    -rw-r----- 1 root shadow 1154 May 25 20:00 /etc/shadow
    #+END_EXAMPLE

    Examples:
    1. set maximum number of days during which password is valid. When
       MAX_DAYS plus LAST_DAYS is less than the current day, the user
       will be required to change the password before being able to
       use the account.
       #+BEGIN_EXAMPLE
       sudo chage yogesh -M 2
       #+END_EXAMPLE

       Passing the number =-1= as the expiry date will remove an
       account expiration date.

*** Strong password
    Force users to set strong passwords using *Pluggable
    Authentication Modules (PAM)*. *PAM* can be configured to
    automatically verify that a password created or modified using the
    *passwd* utility is sufficiently strong. *PAM* configuration is
    implemented using a library called *pam_cracklib.so*, which can
    also be replaced by *pam_passwdqc.so* for more options.

** Securing the boot process and hardware resources
   We can secure the boot process with a secure password to prevent
   someone from bypassing the user authentication step. For systems
   using the GRUB boot loader, for the older GRUB version 1, we can
   invoke *grub-md5-crypt* which will prompt us for a password and
   then encrypt.

   We must then edit =/etc/grub/grub.cfg= file by adding the following
   line below the timeout entry:
   #+BEGIN_EXAMPLE
   password --md5 <encrypted-password>
   #+END_EXAMPLE
   
   We can also force passwords for only certain boot choices rather
   than all.

   We never edit the configuration file, =/boot/grub/grub.cfg=
   directly, rather we edit system configuration files in
   =/etc/grub.d= and then run =update-grub=.

   - refer :: https://help.ubuntu.com/community/Grub2/Passwords

** Hardware Vulnerability
   When hardware is physically accessible, security can be compromised
   by:
*** Key Logging
    Recording the real time activity of a computer used including the
    keys they press. The captured data can either be stored locally or
    transmitted to remote machines.

*** Network sniffing
    Capturing and viewing the network packet level data on our
    network.

*** Live CD
    Booting with a live cd or rescue disk.

*** Remounting and modifying disk content

** Security Policy
   IT security policy should start with requirements on how to
   properly secure physical access to servers and
   workstations. Physical access to a system makes it possible for
   attackers to easily leverage several attack vectors, in a way that
   makes all operating system level recommendations irrelevant.

   The guidelines for security are:

   1. Lock down workstations and servers.
   2. Protect our network link such that it can not be accessed by
      people we do not trust.
   3. Protect our keyboards where passwords are entered to ensure the
      keyboards cannot be tampered with.
   4. Ensure a password protects the BIOS in such a way that system
      cannot be booted with a live or rescue DVD or USB key.

* Network Operations
  A network is a group of computers connected together via a
  communication channels such as cable or wireless.

  Network is used to share devices such as printers and scanners among
  various users. It is also used to share and manage information
  across computers easily.

  Most organizations have both internal network and an internet
  connection for users to communicate with machines and people outside
  the organization. The internet is the largest network in the world
  and is often called the "network of networks".

** IP Address
   Machine connected to the network must have at least one unique
   network address identifier known as the IP (Internet Protocol)
   address. The address is essential for routing packets of
   information through network.

   Packets contains data buffers together with headers which contain
   information about where the packet is going to and coming from, and
   where it fits in the sequence of packets that constitute the
   stream.

   Networking protocols and software are rather complicated due to the
   diversity of machines and operating systems they must deal with, as
   well as the fact that even old standards must be supported.

*** IPv4
    It uses 32-bits for addresses; there are only 2^32 = 4.3 billion
    unique addresses available.
    #+BEGIN_EXAMPLE
    10.4.1.12
    #+END_EXAMPLE

**** IPv4 classes
     IPv4 address consists of four 8-bits sections called octets.
     Network addresses are divided into five classes: A, B, C, D and
     E. Class A, B and C are classified into two parts: *Network
     address (Net ID) and Host address (Host ID)*. The Net ID is used
     to identify the network, while the Host ID is used to identify a
     host in the network. Class D is used for special multicast
     applications and class E is reserved for future/research use.

***** Class A address
      Class A ip addresses use first octet as the Network ID and use
      the other three octets as the Host ID. The first bit of the
      first octet is always set to =0=. So we can use only 7-bits for
      unique network numbers. As a result we can use maximum of 126
      class A networks available (the addresses 0000000 and 1111111
      are reserved). This was only useful when there were few networks
      with large number of hosts.

      Each class A network can have up to 16.7 million unique hosts on
      its network. The range of host address is from 1.0.0.0 to
      127.255.255.255.

***** Class B address
      Class B address use the first two octets of the IP address as
      their Net ID and the last two octets as the Host ID. The first
      two bits of the first octet are always set to binary =10=, so
      there are a maximum of (14-bits) class B networks. The first
      octet of a class B address has values from 128 to 191.

      Each class B network can support a maximum of 65,536 unique
      hosts on its network. The range of host address is from
      128.0.0.0 to 191.255.255.255.

***** Class C address
      Class C address use the first three octets of the IP address as
      their Net ID and the last octet as their Host ID. The first
      three bits of the first octet are set to binary =110=. The first
      octet of a class C address has values from 192 to 223. These are
      most common for smaller networks which don't have many unique
      hosts.

      Each class C network can support up to 256 (8-bit) unique
      hosts. The range of hosts address is from 192.0.0.0 to
      223.255.255.255.

*** IPv6
    It uses 128-bits for addresses; this allows for 3.4 * 10^38
    addresses. It is difficult to move to IPv6 as the two protocols do
    not inter-operate.
    #+BEGIN_EXAMPLE
    2001:0db8:0a0b:12f0:0000:0000:0000:0001
    #+END_EXAMPLE

** IP Address allocation
   A range of IP addresses are requested from Internet Service
   Provider (ISP) by an organization's network administrator. Often
   the choice of which class of IP address given depends on the size
   of network and expected growth needs.

   We can assign IP address to computers over a network manually or
   dynamically. When we assign IP addresses manually, we add *static*
   (never changing) addresses to the network. When we assign IP
   addresses dynamically (they can change every time we reboot or even
   more often), the *Dynamic Host Configuration Protocol* (DHCP) is
   used to assign IP addresses.

*** Manually allocating an IP address
    Before an ip address can be allocated manually, one must identify
    the size of the network by determining the host range; this
    determines which network class (A, B, or C) can be used. The
    *ipcalc* program can be used to ascertain the host range.
    #+BEGIN_EXAMPLE
    $ ipcalc 192.168.0.0/24
    Address:   192.168.0.0          11000000.10101000.00000000. 00000000
    Netmask:   255.255.255.0 = 24   11111111.11111111.11111111. 00000000
    Wildcard:  0.0.0.255            00000000.00000000.00000000. 11111111
    =>
    Network:   192.168.0.0/24       11000000.10101000.00000000. 00000000
    HostMin:   192.168.0.1          11000000.10101000.00000000. 00000001
    HostMax:   192.168.0.254        11000000.10101000.00000000. 11111110
    Broadcast: 192.168.0.255        11000000.10101000.00000000. 11111111
    Hosts/Net: 254                   Class C, Private Internet
    #+END_EXAMPLE

** Network Interfaces
   Network interfaces are a connection channel between a device and a
   network. System can have multiple network interfaces operating at
   once. Specific interfaces can be brought up (activated) or brought
   down (deactivated) at any time.

** ifconfig
   ifconfig command is used to display active network interfaces.

** Network configuration files
   Network configuration files are essential to ensure that interfaces
   function correctly.

   For *Debian* family configuration, the basic configuration file is
   =/etc/network/interfaces=. We use =/etc/init.d/networking start= to
   start the networking configuration.

   For *Fedora* family system configuration, the routing and host
   information is contained in =/etc/sysconfig/network=. The network
   interface configuration script is located at
   =/etc/sysconfig/network-scripts/ifcfg-eth0=. We use
   =/etc/init.d/network start= to start the networking configuration.
   
** Network configuration commands
*** ip addr
    #+BEGIN_EXAMPLE
    $ /sbin/ip addr show
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
      valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
      valid_lft forever preferred_lft forever
    2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 74:86:7a:11:5b:a7 brd ff:ff:ff:ff:ff:ff
    inet 10.1.65.135/24 brd 10.1.65.255 scope global eth0
      valid_lft forever preferred_lft forever
    inet6 fe80::7686:7aff:fe11:5ba7/64 scope link 
      valid_lft forever preferred_lft forever
    3: wlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether bc:85:56:45:3e:8d brd ff:ff:ff:ff:ff:ff
    inet 10.42.0.1/24 brd 10.42.0.255 scope global wlan0
      valid_lft forever preferred_lft forever
    inet6 fe80::be85:56ff:fe45:3e8d/64 scope link 
      valid_lft forever preferred_lft forever
    #+END_EXAMPLE
*** ip route
    #+BEGIN_EXAMPLE
    $ /sbin/ip route show
    default via 10.1.65.1 dev eth0  proto static 
    10.1.65.0/24 dev eth0  proto kernel  scope link  src 10.1.65.135  metric 1 
    10.42.0.0/24 dev wlan0  proto kernel  scope link  src 10.42.0.1  metric 9 
    172.17.0.0/16 dev docker0  proto kernel  scope link  src 172.17.0.1
    #+END_EXAMPLE
*** Ping
    Ping command is used to check whether or not a machine attached to
    the network is online and is responding. It can also be used to
    measure network latency between machines.

    Ping is frequently used for network testing and management.
    #+BEGIN_EXAMPLE
    ping <hostname>
    #+END_EXAMPLE

*** route
    Data moves from source to destination by passing through a series
    of routers and potentially across multiple networks. Servers
    maintain routing table containing the address of each node in the
    network. The *IP routing protocols* enables routers to build up a
    forwarding table that correlates final destinations with the next
    hop address.

    route is used to view and change the ip routing table. We can
    delete, add or modify specific (static) routes to specific hosts
    or networks.

    #+BEGIN_EXAMPLE
    $ route -n
    Kernel IP routing table
    Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
    0.0.0.0         10.1.65.1       0.0.0.0         UG    0      0        0 eth0
    10.1.65.0       0.0.0.0         255.255.255.0   U     1      0        0 eth0
    10.42.0.0       0.0.0.0         255.255.255.0   U     9      0        0 wlan0
    172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
    #+END_EXAMPLE

    Here =0.0.0.0= as gateway means there is no gateway set. The
    destination ip if belongs to the same ip subnet as the interface
    ip it is directly sent to the destination without the need of
    route.

*** traceroute
    traceroute is used to inspect the route that the data packet takes
    to reach the destination host, which makes it quite useful for
    troubleshooting network delays and errors. By using *traceroute*
    we can isolate connectivity issues between hops, which helps
    resolve the issue faster.

    #+BEGIN_EXAMPLE
    traceroute <domain>
    #+END_EXAMPLE

*** ethtool
    Queries network interfaces and can also set various parameters
    such as speed.
    #+BEGIN_EXAMPLE
    $ ethtool eth0
    Settings for eth0:
	Supported ports: [ TP MII ]
	Supported link modes:   10baseT/Half 10baseT/Full 
	                        100baseT/Half 100baseT/Full 
	Supported pause frame use: No
	Supports auto-negotiation: Yes
	Advertised link modes:  10baseT/Half 10baseT/Full 
	                        100baseT/Half 100baseT/Full 
	Advertised pause frame use: Symmetric Receive-only
	Advertised auto-negotiation: Yes
	Link partner advertised link modes:  10baseT/Half 10baseT/Full 
	                                     100baseT/Half 100baseT/Full 
	Link partner advertised pause frame use: No
	Link partner advertised auto-negotiation: Yes
	Speed: 100Mb/s
	Duplex: Full
	Port: MII
	PHYAD: 0
	Transceiver: internal
	Auto-negotiation: on
    Cannot get wake-on-lan settings: Operation not permitted
	Current message level: 0x00000033 (51)
			       drv probe ifdown ifup
	Link detected: yes
    #+END_EXAMPLE

*** netstat
    Displays all the active connections and routing tables. Useful for
    monitoring performance and troubleshooting.
    #+BEGIN_EXAMPLE
    $ netstat -nlp
    #+END_EXAMPLE

*** nmap
    Scans open ports on a network, important for security analysis.
    #+BEGIN_EXAMPLE
    $ sudo nmap localhost
    Starting Nmap 6.40 ( http://nmap.org ) at 2016-06-09 08:20 IST
    Nmap scan report for localhost (127.0.0.1)
    Host is up (0.00032s latency).
    Not shown: 996 closed ports
    PORT     STATE SERVICE
    22/tcp   open  ssh
    80/tcp   open  http
    631/tcp  open  ipp
    3306/tcp open  mysql
    Nmap done: 1 IP address (1 host up) scanned in 0.17 seconds
    #+END_EXAMPLE

*** tcpdump
    Dumps network traffic for analysis.
    #+BEGIN_EXAMPLE
    $ tcpdump -n port 53
    #+END_EXAMPLE

*** iptraf
    Monitors network traffic in text mode.
    #+BEGIN_EXAMPLE
    $ sudo iptraf
    #+END_EXAMPLE

** Browser
   Browsers are used to retrieve, transmit, and explore information
   resources, usually on the *World wide web*. Linux users commonly
   use both graphical and non-graphical browser applications.
 
   Non graphical browsers:
   |-------+--------------------------------------|
   | lynx  | Configurable text-based web browser; |
   |-------+--------------------------------------|
   | links | Based on lynx                        |
   |-------+--------------------------------------|

** wget
   Sometimes we need to download files and information but a browser
   is not the best choice, either because we want to download multiple
   files, or we want to perform the action from a command line or a
   script. *wget* is a command line utility that can capably handle
   the following types of downloads:
   1. Recursive file downloads, where a web page refers to other web
      pages and all are downloaded at once.
   2. Password required downloads.
   3. Multiple file downloads.

   #+BEGIN_EXAMPLE
   $ wget <url>
   #+END_EXAMPLE

** curl
   Besides downloading we may want to obtain information about a URL,
   such as the source code being used. *curl* also allows to save the
   contents of a web page to a file as does *wget*.

   To read the URL type
   #+BEGIN_EXAMPLE
   curl <url>
   #+END_EXAMPLE

   To get the contents of a web page and store it to a file, type
   #+BEGIN_EXAMPLE
   curl -o saved.html http://www.mysite.com
   #+END_EXAMPLE
   The content of the main index file at the website will be saved in
   saved.html.

** ftp
   To transfer files from one machine to another over a network,
   *File Transfer Protocol (FTP)* can be used. This method is built on
   a client-server model.

   *FTP* clients enables to transfer files with remote computers using
   the FTP protocol. Some command line FTP clients are:
   1. ftp
   2. sftp
 
   *sftp* is a secure mode of connection, which uses the *Secure
   Shell (ssh)* protocol. sftp encrypts its data and thus sensitive
   information is transmitted more securely.

   #+BEGIN_EXAMPLE
   ftp -p <server-url>
   #+END_EXAMPLE

** ssh
   ssh is a cryptographic network protocol used for secure data
   communication. It is used for remote services and other secure
   services between two devices.

** scp
   We can also move files securely between two networked hosts. scp
   uses the SSH protocol for transferring data.

* Manipulating Text
** cat
   cat is short for concatenate. It is used to read and print
   files. The main purpose of cat, is to combine multiple files
   together.
   |-------------------------------------+------------------------------|
   | cat file.txt                        | display file content         |
   |-------------------------------------+------------------------------|
   | cat > file.txt                      | write follows into a file    |
   |                                     | terminated by CTRL-D         |
   |-------------------------------------+------------------------------|
   | cat file1.txt file2.txt > file3.txt | Combine file1 and file2,     |
   |                                     | and write into file3         |
   |-------------------------------------+------------------------------|
   | cat file1.txt >> file2.txt          | append contents of file1.txt |
   |                                     | into file2.txt               |
   |-------------------------------------+------------------------------|

** echo
   echo displays(echoes) text.
   #+BEGIN_EXAMPLE
   echo string
   #+END_EXAMPLE
   echo can be used to display a string on standard output (i.e. the
   terminal) or to place in a new file.

   echo is particularly useful for viewing the values of environment
   variables (built-in shell variables).

   The =-e= option enables special character sequences, such as the
   newline character or horizontal tab.
   #+BEGIN_EXAMPLE
   echo -e "this is a test of \n new line"
   #+END_EXAMPLE

** sed
   sed is a powerful text processing tool. It is used to modify
   the contents of a file, usually placing the contents into a new
   file. Its name is an abbreviation for *stream editor*. 

   sed can filter text as well as perform substitutions in data
   streams, working like a churn-mill.

   Data from an input source/file (or stream) is taken and moved to a
   working space. The entire list of operations/modifications is
   applied over the data in the working space and the final contents
   are moved to the standard output space (or stream).

   |------------------------------+-----------------------------------|
   | sed -e command <filename>    | Specify editing commands at the   |
   |                              | command line, operate on file and |
   |                              | put the output on standard out    |
   |------------------------------+-----------------------------------|
   | sed -f scriptfile <filename> | Specify a scriptfile containing   |
   |                              | sed commands, operate on file and |
   |                              | put output on standard out.       |
   |------------------------------+-----------------------------------|
   | sed -i '/^\s*$/d' <filename> | removes empty lines from file     |
   |                              | inplace                           |
   |------------------------------+-----------------------------------|

   Replace first occurrence of pattern with replace_string.
   #+BEGIN_EXAMPLE
   sed s/pattern/replace_string/ file
   #+END_EXAMPLE

   Replace all occurrences of pattern with replace_string.
   #+BEGIN_EXAMPLE
   sed s/pattern/replace_string/g file
   sed s/pattern/replace_string/g file > file2.txt
   #+END_EXAMPLE

   Few more examples:
   #+BEGIN_EXAMPLE
   $ echo day | sed s/day/night
   night

   $ echo "123 abc" | sed 's/[0-9]*/& &/'
   123 123 abc
   #+END_EXAMPLE

** awk
   awk is used to extract and then print specific contents of a file
   and is often used to construct reports. It was created at Bell
   Labs in the 1970s.

   *awk* has following features:
   1. It is a powerful utility and interpreted programming language.
   2. It is used to manipulate data files, retrieving, and processing
      text.
   3. It works well with fields (containing a single piece of data,
      essentially a column) and records (a collection of fields,
      essentially a line in a file).

   |----------------------------------+------------------------------------------------|
   | *Command                         | Usage*                                         |
   |----------------------------------+------------------------------------------------|
   | awk `command` var=value file     | Specify a command directly at the command line |
   |----------------------------------+------------------------------------------------|
   | awk -f scriptfile var=value file | Specify a file that contains the script to be  |
   |                                  | executed along with                            |
   |----------------------------------+------------------------------------------------|


   |-------------------------------------+-----------------------------|
   | *Command                            | Usage*                      |
   |-------------------------------------+-----------------------------|
   | awk '{print $0}' /etc/passwd        | Print entire file           |
   |-------------------------------------+-----------------------------|
   | awk -F: '{print $1}' /etc/passwd    | Print first field (column)  |
   |                                     | of every line, separated by |
   |                                     | space                       |
   |-------------------------------------+-----------------------------|
   | awk -F: '{print $1 $6}' /etc/passwd | Print first and sixth field |
   |                                     | of every line.              |
   |-------------------------------------+-----------------------------|

   The awk command/action in awk needs to be surrounded with
   apostrophes (or single-quote (')). Otherwise it will throw error as
   follows:
   #+BEGIN_EXAMPLE
   awk: line 2: missing } near end of file
   #+END_EXAMPLE

* Regular Expressions
  Regular expression are text strings used for matching a specific
  *pattern*, or to search for a specific location, such as the start
  or end of a line or a word. Regular expressions can contain both
  normal characters or so-called metacharacters, such as * and $.

  |-----------------+----------------------------|
  | *Search Pattern | Usage*                     |
  |-----------------+----------------------------|
  | .(dot)          | Match any single character |
  |-----------------+----------------------------|
  | $               | Match end of string        |
  |-----------------+----------------------------|
  | *               | Match preceding item 0     |
  |                 | or more times              |
  |-----------------+----------------------------|

** Using regular expression and search patterns
   #+BEGIN_EXAMPLE
   the quick brown fox jumped over the lazy dog
   #+END_EXAMPLE

   |---------+------------------------|
   | Command | Example                |
   |---------+------------------------|
   | a..     | matches lazy           |
   |---------+------------------------|
   | ..$     | matches og             |
   |---------+------------------------|
   | l.*     | matches lazy dog       |
   |---------+------------------------|
   | l.*y    | matches lazy           |
   |---------+------------------------|
   | the.*   | matches whole sentence |
   |---------+------------------------|

* Miscellaneous text utilities
** grep
   grep is extensively used as a primary text searching tool. It scans
   files for specified patterns and can be used with regular
   expressions as well as simple strings
  
   |--------------------------------+---------------------------------------|
   | Command                        | Usage                                 |
   |--------------------------------+---------------------------------------|
   | grep [pattern] <filename>      | Search for a pattern in a file        |
   |                                | and print all matching lines          |
   |--------------------------------+---------------------------------------|
   | grep -v [pattern] <filename>   | Print all lines that do not           |
   |                                | match pattern                         |
   |--------------------------------+---------------------------------------|
   | grep -C 3 [pattern] <filename> | Print context of lines (specified     |
   |                                | number of lines above and below       |
   |                                | the pattern) for matching the pattern |
   |--------------------------------+---------------------------------------|

** tr
   *tr* is used to translate specified characters into other
   characters or to delete them.
   #+BEGIN_EXAMPLE
   $ tr [options] set1 [set2]
   #+END_EXAMPLE

   It is a good practise to surround these sets by apostrophes in
   order to have the shell ignore that they mean something special to
   the shell.
   
   #+BEGIN_EXAMPLE
   $ tr '{}' '()' < inputfile > outputfile
   $ cat file | tr a-z A-Z
   #+END_EXAMPLE

** tee
   tee takes the output from any command, and while sending it to
   standard output, it also saves it to a file. In other words, it
   "tees" the output stream from the command: one stream is displayed
   on the standard output and the other is saved to a file.

   #+BEGIN_EXAMPLE
   ls -l | tee lsoutput
   #+END_EXAMPLE

** wc
   wc (word count) counts the number of characters, words and lines in
   a file or list of files.

** cut
   cut is used for manipulating column-based files and is designed to
   extract specific columns. Default column separator is the tab
   character. A different delimiter can be given as a command option.

   using cut
   #+BEGIN_EXAMPLE
   ls -l | cut -d" " -f5
   #+END_EXAMPLE

   using awk
   #+BEGIN_EXAMPLE
   ls -l | awk '{print $5}'
   #+END_EXAMPLE

* Working with large files
  System administrators need to work with configuration files, log
  files, text files and documentation files.

  Directly opening files in an editor will cause issue, due to high
  memory utilization, as an editor will usually try to read the whole
  file into memory first. 

** less
   We can use =less= command to view the contents of such a large
   file, scrolling up and down page by page without the system having
   to place the entire file in memory before starting. This is mush
   faster than using a text editor.

   #+BEGIN_EXAMPLE
   $ less <filename>
   $ cat <filename> | less
   #+END_EXAMPLE

** head
   head reads the first few lines of each named file (10 by default)
   and displays it on standard output.
   #+BEGIN_EXAMPLE
   head -n 5 file
   #+END_EXAMPLE

** tail
   tail displays the last few lines of each named file on standard
   output.
   #+BEGIN_EXAMPLE
   tail -n 15 log.txt
   tail -15 log.txt
   #+END_EXAMPLE

   To continually monitor new output in a growing log file:
   #+BEGIN_EXAMPLE
   tail -f /var/log/apache2/access.log
   #+END_EXAMPLE
   This command will continually display any new lines of output in
   the file, as soon as they appear. It enables to monitor any current
   activity that is being reported and recorded.
   
** strings
   strings is used to extract all printable character strings found in
   the file or files given as arguments. It is useful in locating
   human readable content embedded in binary files: for text one can
   just use grep.

   To search for a string in spreadsheet.
   #+BEGIN_EXAMPLE
   strings book1.xls | grep my_string
   #+END_EXAMPLE

** z commands
   For many commonly-used file and text manipulation programs there is
   also a version especially designed to work directly with compressed
   files. These utilities have the letter z prefixed to their name.
   1. zcat
   2. zless
   3. zgrep
   4. zdiff

* Printing
  To manage printers and print directly from a computer or across a
  networked environment, we need to know how to configure and install
  a printer. Printing requires software that converts the information
  from the application to a language that a printer can understand.

  The Linux standard for printing software is the *Common Unix
  Printing System (CUPS)*. CUPS uses modular printing system which
  accommodates a wide variety of printers and also processes various
  data formats.

  The only time we need to configure printer is when we use it for the
  first time.

** CUPS components
*** Scheduler
    Scheduler manages the print jobs through the use of configuration
    files. It allow users to get printer status, schedule jobs.
    
    CUPS has a browser-based interface which allows to view and
    manipulate the order and status of pending print jobs.
    
*** Configuration files
    The system reads its configuration from several configuration
    files, the two most important of which are =cupsd.conf= and
    =printers.conf=. These and all other CUPS related configuration
    files are located at =/etc/cups=.
   
    =cupsd.conf= is where most system-wide settings are located; it
    does not contain any printer-specific details. Most of the
    settings available in the file relate to network security,
    i.e. which systems can access CUPS network capabilities, how
    printers are advertised on the local network, what management
    features are offered, and so on.

    =printers.conf= is for configuring printer-specific settings. For
    every printer connected to the system, a corresponding section
    describes the printer's status and capabilities. This file is
    generated only after adding the printer to the system and should
    not be modified by hand.

*** Job files
    CUPS stores print requests as files under the =/var/spool/cups=
    directory (these can actually be accessed before a document is
    sent to a printer). Data files are prefixed with the letter *d*
    while control files are prefixed with the letter *c*. After a
    printer successfully handles a job, data files are automatically
    removed. These data files belong to what is commonly known as
    the *print queue*.

*** Log files
    Log files are placed inside the =/var/log/cups= and are used by
    the scheduler to record activities that have taken place. These
    files include access, error and page records.
   
    To view log files type =ls -l /var/log/cups=.

*** Filters,  Printer Drivers, Backend
    When we execute a print command, scheduler validates the command
    and processes the print job creating job files according to the
    settings specified in configuration files. Simultaneously, the
    scheduler records activities in the log files. Job files are
    processed with the help of the filter, printer driver, and
    backend, and then sent to the printer.

** CUPS daemon
   Managing cups daemon is simple; all management features are
   wrapped around the cups init script, which can be easily started,
   stopped and restarted.

   1. Install cups on ubuntu platform using following command:
      #+BEGIN_EXAMPLE
      sudo apt-get install cups
      #+END_EXAMPLE

   2. Start, restart and stop:
      #+BEGIN_EXAMPLE
      sudo /etc/init.d/cups start
      sudo /etc/init.d/cups stop
      sudo /etc/init.d/cups restart
      sudo /etc/init.d/cups status
      #+END_EXAMPLE

   3. Set cups daemon to start at boot time:
      #+BEGIN_EXAMPLE
      sudo update-rc.d cups enable
      #+END_EXAMPLE
   
   4. Set cups demon to not start at boot time:
      #+BEGIN_EXAMPLE
      sudo update-rc.d cups disable
      #+END_EXAMPLE

** CUPS web interfaces
   CUPS comes with its own web server, which makes a configuration
   interface available via a set of CGI scripts.

   The web interface allows to:
   - Add and remove local/remote printers.
   - Configure printers:
     - Local/remote printers
     - Share a printer as a CUPS server
   - Control print jobs:
     - Monitor jobs
     - Show completed or pending jobs
     - Cancel or move jobs

   The cups web interface is available on browser at:
   http://localhost:631

** Printing from the command line interface
   *CUPS* provides two command-line interfaces, descended from the
   System V and BSD flavours of Unix. We can use either *lp* or *lpr*
   to print text, PostScript, pdf and image file.

   These command are useful in cases where printing operations must
   be automated from shell scripts.

*** lp
    |--------------------------+----------------------------------------|
    | *Command                 | Usage*                                 |
    |--------------------------+----------------------------------------|
    | lp <filename>            | To print the file to default printer   |
    |--------------------------+----------------------------------------|
    | lp -d printer <filename> | To print to a specific printer (useful |
    |                          | if multiple printers are available)    |
    |--------------------------+----------------------------------------|
    | lp -n number <filename>  | To print multiple copies               |
    |--------------------------+----------------------------------------|
    | lpoptions -d printer     | To set the default printer             |
    |--------------------------+----------------------------------------|
    | lpq -a                   | To show the queue status               |
    |--------------------------+----------------------------------------|
    | lpadmin                  | To configure printer queues            |
    |--------------------------+----------------------------------------|

** Managing print jobs
   |--------------------------+--------------------------------------|
   | Command                  | Usage                                |
   |--------------------------+--------------------------------------|
   | lpstat -p -d             | To get a list of available printers, |
   |                          | along with their status              |
   |--------------------------+--------------------------------------|
   | lpstat -a                | To check the status of all connected |
   |                          | printers, including job numbers      |
   |--------------------------+--------------------------------------|
   | cancel job-id            | To cancel a print job                |
   |--------------------------+--------------------------------------|
   | lpmove job-id newprinter | To move a print job to new printer   |
   |--------------------------+--------------------------------------|
  
** Manipulating Postscripts and PDF files
*** Postscripts
    PostScript is a standard *page description language*. It
    effectively manages scaling of fonts and vector graphics to
    provide quality printouts. It is purely a text format that
    contains the data fed to a PostScript interpreter.
   
*** pdftk
    Using pdf tool kit (pdftk) we can merge, split, or rotate PDF
    files; not all of these operations can be achieved while using a
    PDF viewer. PDF tool kit *pdftk* allows sophisticated operations
    such as:

    - Merging/splitting/rotating pdf files
    - Repairing corrupted pdf pages
    - Pulling single page from a file
    - Encrypting and decrypting pdf filse
    - Adding, updating, and exporting a PDF's metadata
    - Exporting bookmarks to a text file
    - Filling out PDF forms

    pdftk can be installed using following command in ubuntu
    #+BEGIN_EXAMPLE
    sudo apt-get install pdftk
    #+END_EXAMPLE

    Example: Merge two documents 1.pdf and 2.pdf. The output will be
    saved to 12.pdf.
    #+BEGIN_EXAMPLE
    pdftk 1.pdf 2.pdf cat output 12.pdf
    #+END_EXAMPLE
    
*** encrypting pdf files
    PDF files containing confidential information can be encrypted by
    applying a password to it using the =user_pw= option.

    #+BEGIN_EXAMPLE
    $ pdftk public.pdf output private.pdf user_pw PROMPT
    #+END_EXAMPLE

*** pdf tools
**** pdfinfo
     It can extract information about pdf files, especially when the
     files are very large or when a graphical interface is not
     available.

**** flpsed
     It can add data to a PostScript document. This tool is very
     useful for filling in forms or adding short comments into the
     document.

**** pdfmod
     Its a simple application that provides a graphical interface for
     modifying PDF documents. Using this tool we can reorder, rotate
     and remove pages; export images from a document; edit the title,
     subject and author; add keywords; and combine documents using
     drag-and-drop action.

     I tried exporting an image from a pdf document, but the image was
     damaged and not properly visible.

*** Creating pdf files
    enscript package can be used to create a postscript file.

    Example:
    #+BEGIN_EXAMPLE
    $ enscript -p syslog.ps /var/log/syslog
    $ ps2pdf syslog.ps
    #+END_EXAMPLE

* Bash Shell Scripting
** Introduction
   Shell is a command line interpreter which provides the user
   interface for terminal windows. It can also be used to run scripts,
   even in non-interactive sessions without a terminal window, as if
   the commands were being directly typed in.

   Example executing following command in the terminal
   #+BEGIN_EXAMPLE
   $ find . -iname '*.c' -ls
   #+END_EXAMPLE

   is equivalent to executing following shell script
   #+BEGIN_EXAMPLE
   #!/bin/bash
   find . -iname '*.c' -ls
   #+END_EXAMPLE

   The first line of the script starts with =#!=, contains the full
   path of the command interpreter (in this case =/bin/bash=) that is
   to be used on the file.

** Shell choices
   Linux provides a wide choices of shells, exactly what is available
   on the system is listed in =/etc/shells= file. Typical choices are:
   #+BEGIN_EXAMPLE
   /bin/sh
   /bin/bash
   /bin/tcsh
   /bin/csh
   /bin/ksh
   #+END_EXAMPLE
** Return Values
   All shell scripts generate a return value upon finishing execution;
   the value can be set with the =exit= statement. Return values
   permit a process to monitor the exit status of another process,
   often in a parent-child relationship. This helps to determine how
   this process terminated and take any appropriate steps necessary,
   contingent(dependent) on success or failure.
   
   Return values are stored in the environment variable, and can be
   viewed by =ehco $?=.
  
   Example:
   #+BEGIN_EXAMPLE
   #!/bin/bash
   echo "Please enter your name"
   read name
   echo "Hi $name!"
   exit 0
   #+END_EXAMPLE

** Syntaxes
   |-------------+--------------------------------------|
   | *Characters | Description*                         |
   |-------------+--------------------------------------|
   | "#"         | Used to add a comment, except        |
   |             | when used as \#, or as #! when       |
   |             | starting a script.                   |
   |-------------+--------------------------------------|
   | \           | Used at the end of the line to       |
   |             | indicate continuation of the line    |
   |-------------+--------------------------------------|
   | ;           | Used to interpret what follows       |
   |             | is a new command.                    |
   |-------------+--------------------------------------|
   | "$"         | Indicates what follows is a variable |
   |-------------+--------------------------------------|

** Multiple commands in one line
   1. The three commands in the following example will all execute
      even if the ones preceding them fails.
      #+BEGIN_EXAMPLE
      $ make; make install; make clean
      #+END_EXAMPLE

   2. Abort subsequent commands if one fails, using "and (&&)"
      operator.
      #+BEGIN_EXAMPLE
      $ make && make install && make clean
      #+END_EXAMPLE

   3. Proceed until something succeeds and then stop executing any
      further steps, using "or (||)" operator.
      #+BEGIN_EXAMPLE
      $ cat file1  || cat file2 || cat file3
      #+END_EXAMPLE

** Functions
   #+BEGIN_EXAMPLE
   function_name () {
       echo "This is a sample function";
   }
   #+END_EXAMPLE

   Arguments passed to the function can be referred as $1, $2 and so
   on.
   
   Example: Input number is used to call the function with that
   number in its name.
   #+BEGIN_EXAMPLE
   #!/bin/bash
   
   func1() {
   echo "This message is from function 1"
   
   }
   
   func2() {
   echo "This message is from function 2"
   
   }
   
   func3() {
   echo "This message is from function 3"
   
   }
   
   echo "Enter 1, 2 or 3"
   
   read variable
   
   func$variable
   #+END_EXAMPLE

   Example: An arithmetic example, a simple calculator. Program checks
   if the number of arguments passed are less than 3, then it prints
   the usage message. Otherwise it does computation on the provided
   numbers based on the argument passed. Note how the if condition is
   constructed with the use of =echo= and =grep -q= commands. If
   commands successfully executes it will return true(0) and if it
   fails it will return false(1). "If" statement will act according to
   the exit status of command.
   #+BEGIN_EXAMPLE
   #!/bin/bash

   if [ $# -lt 3 ]
   then
   echo "please provide input in the following format: a number1 number2"
   exit 1
   else
   choice=$1
   number1=$2
   number2=$3
   fi
   
   if echo $choice | egrep -q 'a' 
   then
   answer=$(( $number1 + $number2 ))
   else if echo $choice | egrep -q 'm' 
   then
   answer=$(( $number1 * $number2 ))
   else if echo $choice | egrep -q 's' 
   then
   answer=$(( $number1 - $number2 ))
   else if echo $choice | egrep -q 'd' 
   then
   answer=$(( $number1 / $number2 ))
   fi
   fi
   fi
   fi
   
   echo $answer
   #+END_EXAMPLE

** Built-in commands
   Types of commands:
   1. Compiled application
   2. Built-in bash commands
   3. Other scripts

   Compiled applications are binary executable files that we can find
   on the filesystem. Example rm, ls, df, vi.

   *bash* has many built-in commands which can only be used to
   display the output within a terminal shell or shell
   script. Example cd, pwd, echo, read and logout.

** Command substitution
   Command substitution allows to substitute the result of a command
   as a portion of another command. It can be done in two ways:
   
   - By enclosing the inner command with backticks =`=
   - By enclosing the inner command in =$()=

   No matter the method, the inner command will be executed in a newly
   launched shell environment, and the standard output of the shell
   will be inserted where the command substitution was done.
   
   =$()= method allows command nesting. New scripts should always use
   this modern method.
   #+BEGIN_EXAMPLE
   $ cd /lib/modules/$(uname -r)/
   #+END_EXAMPLE

** Environment Variables
   Almost all scripts use variables containing a value, which can be
   used anywhere in the script. These variables can either be user or
   system defined. Many applications use such *environment variables*
   for supplying inputs, validation, and controlling behaviour.

   Examples of standard environment variables are =HOME=, =PATH=, and
   =HOST=. These environment variable can be referenced with the =$=
   symbol as in =$HOME=. We can view and set the value of environment
   variables.
   #+BEGIN_EXAMPLE
   echo $PATH
   #+END_EXAMPLE

   #+BEGIN_EXAMPLE
   test=2
   #+END_EXAMPLE

   We can get the list of environment variables with the =env=, =set=,
   or =printenv= command.

** Exporting variable
   By default, the variables created within a script are available
   only to subsequent steps of that script. Any child processes
   (sub-shells) does not have access to the values of these variables.

   To make the variable accessible to child processes, variable must
   be promoted to environment variables using the =export=
   command. One of the following ways can be followed:

   #+BEGIN_EXAMPLE
   $ export variable=value
   #+END_EXAMPLE

   #+BEGIN_EXAMPLE
   $ variable=value
   $ export variable
   #+END_EXAMPLE

   While child processes are allowed to modify the value of a
   exported variables, the parent will not see any changes, exported
   variables are not shared, but only copied.

   It is important to note that =export= doesn't make it available to
   parent processes. That is, specifying and exporting a variable in
   a spawned process does not make it available in the process that
   launched it.

   If we define variable without =export=, then the variable scope is
   restricted to the shell and is not available to any other process.
   We use this for loop variables, temporary variables etc.

   #+BEGIN_EXAMPLE
   $ variable=value
   #+END_EXAMPLE

** Script parameters
   Users often need to pass parameter values to a script, such as a
   filename, data, etc.

   Within a script, the parameters or an argument is represented with
   a =$= and a number.

   |------------+-----------------------------|
   | Parameter  | Meaning                     |
   |------------+-----------------------------|
   | $0         | script name                 |
   |------------+-----------------------------|
   | $1         | First parameter             |
   |------------+-----------------------------|
   | $2,$3,etc. | Second,third parameter etc. |
   |------------+-----------------------------|
   | $*         | All parameters              |
   |------------+-----------------------------|
   | $#         | Number of arguments         |
   |------------+-----------------------------|

** Input and Output redirection
   The input of a command can be read from a file. The process of
   reading input from a file is called input redirection.

   #+BEGIN_EXAMPLE
   $ wc -l < file.txt
   #+END_EXAMPLE

   The process of diverting the output of a program to a file is
   called output redirection.

   Example:
   #+BEGIN_EXAMPLE
   $ free > /tmp/free.out
   #+END_EXAMPLE

   To append the output to already existing file use =>>=.
   #+BEGIN_EXAMPLE
   $ free >> /tmp/free.out
   #+END_EXAMPLE

** If statement
   The syntax for an =if= statement is as follows:
   #+BEGIN_EXAMPLE
   if TEST-COMMANDS; then CONSEQUENT-COMMANDS; fi
   #+END_EXAMPLE

   #+BEGIN_EXAMPLE
   if condition
   then
   statements
   else
   statements
   fi
   #+END_EXAMPLE

   Example:
   #+BEGIN_EXAMPLE
   #!/bin/bash
   
   file=$1
   
   if [ -f $file ]
   then
   echo -e "file $file exists"
   else
   echo -e 'file does not exists!'
   fi
   #+END_EXAMPLE
   
   Following is a simple and learning example of the *else if*
   condition, using =elif= directive.

   #+BEGIN_EXAMPLE
   #!/bin/bash

   echo "simple calculator"
   
   echo "Enter variables:"
   read var1
   read var2
   
   echo "Enter number corresponding to operator!"
   echo "1. addition"
   echo "2. subtraction"
   echo "3. multiplication"
   echo "4. division"
   
   read operator
   
   if [ $operator -eq 1 ] 
   then
   echo "addition result " $(($var1 + $var2))
   elif [ $operator -eq 2 ] 
   then
   echo "subtraction result " $(($var1 - $var2))
   elif [ $operator -eq 3 ] 
   then
   echo "multiplication result " $(($var1 * $var2))
   elif [ $operator -eq 4 ] 
   then
   echo "division result " $(($var1 / $var2))
   else
   echo "invalid operator"
   fi
   #+END_EXAMPLE

   String comparison example:

   #+BEGIN_EXAMPLE
   if [ string1 == string2 ]; then
       ACTION
   fi
   #+END_EXAMPLE

   Following is an interesting program which checks whether the input
   entered by user is a number or not, and then take actions
   accordingly.

   #+BEGIN_EXAMPLE
   echo "Enter 1 or 2"
   read number
   
   if echo $number | egrep -q '^[0-9]+$'; then
   if [ $number -eq 1 ] 
   then
   variable=1
   export variable
   else
   variable=2
   export variable
   fi
   else
   variable=123
   export variable
   fi
   
   echo $variable
   #+END_EXAMPLE

** Numerical tests
   We can use specially defined operators with the if statement to
   compare numbers.
   |-----------+--------------------------|
   | *Operator | Meaning*                 |
   |-----------+--------------------------|
   | -eq       | Equal to                 |
   |-----------+--------------------------|
   | -lt       | less than                |
   |-----------+--------------------------|
   | -gt       | greater than             |
   |-----------+--------------------------|
   | -ne       | not equal to             |
   |-----------+--------------------------|
   | -ge       | greater than or equal to |
   |-----------+--------------------------|
   | -le       | less than or equal to    |
   |-----------+--------------------------|

** Arithmetic Expressions
   Arithmetic expressions can be evaluated in the following three
   ways:
   1. expr 8 + 8
   2. let x=( 1 + 2 ); echo $x
   3. echo $((x+1))
  
* Advanced Bash Scripting
** String Manipulation
   String operators include those that do comparison, sorting, and
   finding the length.
   
   |--------------------+----------------------------------------|
   | *Operator          | Meaning*                               |
   |--------------------+----------------------------------------|
   | string1 > string2  | Compares the sorting order of string1  |
   |                    | string2                                |
   |--------------------+----------------------------------------|
   | string1 == string2 | Compares the character in string1 with |
   |                    | the characters in string2              |
   |--------------------+----------------------------------------|
   | mylen1=${#string1} | Saves the length of string1 in the     |
   |                    | variable mylen1                        |
   |--------------------+----------------------------------------|

** Boolean Expression
   |-----------+-----------+---------------------------------------|
   | *Operator | Operation | Meaning*                              |
   |-----------+-----------+---------------------------------------|
   | &&        | AND       | The action will be performed only if  |
   |           |           | both the conditions evaluate to true. |
   |-----------+-----------+---------------------------------------|
   |           | OR        | The action will be performed if any   |
   |           |           | of the conditions evaluate to true.   |
   |-----------+-----------+---------------------------------------|
   | !         | NOT       | The action will be performed only if  |
   |           |           | the condition evaluates to false.     |
   |-----------+-----------+---------------------------------------|
   
   Example: =[ $number1 -gt $number2 ]= returns *TRUE* if number1 is
   greater than number2.

** Parts of a string
   To extract first character of a string.
   #+BEGIN_EXAMPLE
   ${string:0:1}
   #+END_EXAMPLE
   Here zero is the offset in the string (i.e., which character to
   begin from) where the extraction needs to start and 1 is the
   number of characters to be extracted.

   To extract all characters in a string after a dot(.), we can use
   the following expression:
   #+BEGIN_EXAMPLE
   ${string#*.}
   #+END_EXAMPLE
   
** Examples
   Test status of ping command, to check if machine is reachable or
   not.
   #+BEGIN_EXAMPLE
   #!/bin/bash

   ip=$1
   
   if [ ! -z $ip ]
   then
   ping -c 1 $ip > /dev/null
   if [ $? -eq 0 ] 
   then
   echo "Machine is reachable and running!"
   else
   echo "Machine is not reachable!"
   fi
   else
   echo "IP address is not provided!"
   fi
   #+END_EXAMPLE

   Test if file exists or not.
   #+BEGIN_EXAMPLE
   #!/bin/bash

   file=$1
   
   if [ -f $file ];
   then
   echo "File $file exists!"
   else
   echo "File $file does not exist!"
   fi
   #+END_EXAMPLE
   
** Looping constructs
   In loop construct the set of commands that are to be executed
   should be enclosed between =do= and =done=.

   1. for loop example: Objective is to find the type of files from
      the filename extension.
      #+BEGIN_EXAMPLE
      #!/bin/bash
      
      for x in $(ls)
      do
      ext=${x##*.}
      echo $ext
      case $ext in
      c) echo "$x : c source file";;
      sh) echo "$x : bash source file";;
      txt) echo "$x : text file";;
      *) echo "$x: unknown file type";;
      esac
      done
      #+END_EXAMPLE

      - Points to note in the above example ::
        1. extension of file is extracted using double hash "{x##*.}"
        2. case construct has to be closed by "esac"
        3. patterns are not enclosed within double quotes
   2. while loop example: Objective is to display the contents of an
      existing file. 
      #+BEGIN_EXAMPLE
      #!/bin/bash

      echo "Enter the absolute path of the file to be read"
      read file
      exec <$file # redirect stdin to a file
      while read line
      do
      echo "$line"
      done
      #+END_EXAMPLE
      - Points to note in the above example ::
	1. stdin is redirected to a file using 'exec' command.
        2. "$line" is enclosed within double quotes, to avoid
           interpretation of any special characters by shell.
      #+BEGIN_EXAMPLE
      #!/bin/bash

      echo "Enter the absolute path of the file to be read"
      read file
      exec 4<$file # create a file descriptor
      exec <&4 # redirects stdin to a file
      while read line
      do
      echo "$line"
      done
      #+END_EXAMPLE

** Script Debugging
   Debugging helps to troubleshoot resolve errors, and is one of the
   most important tasks a system administrator performs.

   Before fixing an error(bug), it is vital to know its source.

   In bash shell, we can run a script in debug mode by doing =bash -x
   ./script.sh=. Debug mode helps identify error because:
   1. It traces and prefixes each command with the + character.
   2. It displays each command before executing it.
   3. It can debug selected parts of a script with:
      #+BEGIN_EXAMPLE
      set -x    # turns on debugging
      ...
      set +x    # turns off debugging
      #+END_EXAMPLE

** Creating temp files and directories
   Temporary files and directories are meant to store data for a short
   time. While we can use =touch= command to create a temporary file,
   this may make it easy for hackers to gain access to our data.

   The best practise is to create random and unpredictable filenames
   for temporary storage. One way to do this is with the *mktemp*
   program.

   #+BEGIN_EXAMPLE
   TEMP=$(mktemp /tmp/tempfile.XXXXXXXX)
   TEMP2=$(mktemp ~/temp.XXXXXXXX)
   TEMPDIR=$(mktemp -d /tmp/tempfile.XXXXXXXX)
   #+END_EXAMPLE

   The =XXXXXXXX= is replaced by the mktemp utility with random
   characters to ensure the name of the temporary files can not be
   easily predicted and is only known within the program.
   
** Example of creating a temporary file and directory
   If someone creates a symbolic link from known temporary file used
   by root to the =/etc/passwd= file, like this:
   #+BEGIN_EXAMPLE
   ln -s /etc/passwd /tmp/tempfile
   #+END_EXAMPLE

   There could be a big problem if a script run by the root has a
   line like this:
   #+BEGIN_EXAMPLE
   echo $var > /tmp/tempfile
   #+END_EXAMPLE
   The password file will be overwritten by the temporary file
   contents.

   To prevent such a situation make sure to randomize the temporary
   filenames by replacing the above line with the following lines:
   #+BEGIN_EXAMPLE
   TEMP=$(mktemp /tmp/tempfile.XXXXXXXX)
   echo $var > $TEMP
   #+END_EXAMPLE

** Discarding output with /dev/null
   Certain commands like find will produce voluminous amounts of
   output which can overwhelm the console. To avoid this, we can
   redirect the large output to a special file (a device node) called
   =/dev/null=.

   It discards all the data that gets written to it and never returns
   a failure on write operations.
   #+BEGIN_EXAMPLE
   find / -iname *.txt > /dev/null
   #+END_EXAMPLE
   
** Random numbers and data
   It is often useful to generate random numbers and other random
   data when performing tasks such as:
   1. Performing security-relates tasks
   2. Reinitializing storage devices
   3. Erasing and/or obscuring existing data
   4. Generating meaningless data to be used for tests

   Such random numbers can be generated by using the "$RANDOM"
   environment variable, which is derived from the linux kernel's
   built-in random number generator, or by the OpenSSL library
   function which uses, the FIPS140 algorithm to generate random
   numbers for encryption.

   #+BEGIN_EXAMPLE
   $ echo $RANDOM
   23390
   $ echo $RANDOM
   10182
   $ echo $RANDOM
   17315
   #+END_EXAMPLE

** How kernel generate random numbers
   - Hardware random number generator ::
	Some servers have hardware random number generators that take
        input noise signals such as thermal noise and photoelectric
        effect. Then a *transducer* converts this noise into electric
        signal, and *A-D converter* then converts this into a digital
        number which is considered as a random number.

   - Software random number generator ::
	Most common computer do not contain such specialized hardware
        and instead rely on events created during booting to create
        raw data needed.

   Regardless of which of these sources used to generate random number
   the system maintains a so-called *entropy pool* of these digital
   numbers/random bits. Random numbers are created from this entropy
   pool.

   The linux kernel offers the */dev/random* and */dev/urandom* device
   nodes which draw on the entropy pool to generate random numbers.

   #+BEGIN_EXAMPLE
   $ ls -l /dev/*random
   crw-rw-rw- 1 root root 1, 8 Jul 19 07:34 /dev/random
   crw-rw-rw- 1 root root 1, 9 Jul 19 07:34 /dev/urandom
   #+END_EXAMPLE

   */dev/random* is used where high quality randomness is required,
   such as one time pad or key generation, but it is relatively slow
   to provide values. */dev/urandom* is faster and suitable (good
   enough) for most cryptographic purposes.

   When entropy pool is empty, =/dev/random= is blocked and does not
   generate any number until additional environmental noise (network
   traffic, mouse movement, etc.) is gathered whereas =/dev/urandom=
   reuses the internal pool to produce more pseudo-random bits.

* Bash examples
  1. Input a number as argument and script converts that into a month
     name.
     #+BEGIN_EXAMPLE
     #!/bin/bash
     
     if [ $# -eq 0 ] 
     then
     echo "please provide a number between 1 and 12"
     exit 1
     fi
     
     month=$1
     
     case $month in
     1) echo "Jan";;
     2) echo "Feb";;
     3) echo "March";;
     4) echo "April";;
     5) echo "May";;
     6) echo "June";;
     7) echo "July";;
     8) echo "Aug";;
     9) echo "Sept";;
     10) echo "Oct";;
     11) echo "Nov";;
     12) echo "Dec";;
     *) echo "Please provide a number between 1 and 12"
     exit 2
     esac
     
     exit 0
  #+END_EXAMPLE
* Processes
** Objectives
   - Describe what a process is and distinguish between types of
     processes.
   - Enumerate process attributes.
   - Manage processes using *ps* and *top* command.
   - Understand the use of load averages other process metrics.
   - Manipulate processes by putting them in background and restoring
     them to foreground.
   - Use *at*, *cron*, and *sleep* to schedule processes in the
     future or pause them.
** What is a process
   A process is an instance of one or more related tasks(threads)
   executing on the computer. It is not the same as program or a
   command; a single program may actually start several processes
   simultaneously. Some processes are independent of each other and
   others are related. A failure of one process may or may not affect
   the others running on the system.

   Process use many system resources, such as memory, CPU cycles, and
   peripheral devices such as printers and displays. The operating
   system (especially the kernel) is responsible for allocating a
   proper share of these resources to each process and ensuring
   overall optimum utilization.

** Process types
   A terminal window (one kind of command shell), is a process that
   runs as long as needed. We can also run programs in the background,
   which means they become *detached* from the shell.

   Process can be of different types according to the task being
   performed. Following table list different process types along with
   their descriptions and examples.

   |----------------+--------------------------------------------------+----------------|
   | *Process type  | Description                                      | Example*       |
   |----------------+--------------------------------------------------+----------------|
   | Interactive    | Need to be started                               | bash, firefox, |
   | Processes      | by a user                                        | top            |
   |----------------+--------------------------------------------------+----------------|
   | Batch          | Automatic processes                              | updatedb       |
   | Processes      | which are scheduled from                         |                |
   |                | and then disconnected from                       |                |
   |                | the terminal. These tasks                        |                |
   |                | are queued and work on a                         |                |
   |                | *FIFO* basis                                     |                |
   |----------------+--------------------------------------------------+----------------|
   | Daemons        | Server processes that run                        | httpd, sshd,   |
   |                | continuously. Many are launched                  | xinetd         |
   |                | during system startup and then                   |                |
   |                | wait for a user or system request                |                |
   |                | indicating that their service is                 |                |
   |                | required.                                        |                |
   |----------------+--------------------------------------------------+----------------|
   | Threads        | Lightweight processes. These are tasks           | firefox,       |
   |                | that run under the umbrella of a main process,   | gnome-terminal |
   |                | sharing memory and other resources. But are      |                |
   |                | scheduled and run by the system. An individual   |                |
   |                | thread can end without terminating the main      |                |
   |                | process, and main process can create new threads |                |
   |                | at any time.                                     |                |
   |----------------+--------------------------------------------------+----------------|
   | Kernel threads | Threads that user neither create nor terminate,  | kswapd0,       |
   |                | and have little control over. Tasks such as      | migration,     |
   |                | moving threads from one cpu to another.          | ksoftirqd      |
   |----------------+--------------------------------------------------+----------------|

** Process states
   - running :: It means it is either currently executing instructions
                on a CPU, or is currently waiting for a share (or time
                slice) so it can run. In this state process is
                sitting on a run queue.

   - sleeping :: It means process is waiting for something to
                 happen. In this state process is sitting on a wait
                 queue.

   - zombie :: It means child process terminated but its parent has
               not asked for its state. It is not alive, but still
               shows up in the system's list of processes.
   
** Process and thread IDs
   The operating system keeps track of processes by assigning each
   process a unique *ID*. This id is used to track process state,
   resource usages and other characteristics.

   New PIDs are assigned in ascending order as processes are
   born. Thus PID 1 denotes the *init* process (initialization
   process), and succeeding processes are gradually assigned higher
   numbers.
   
   |--------------------------+----------------------------|
   | *ID type                 | Description*               |
   |--------------------------+----------------------------|
   | Process ID (PID)         | Unique process ID number   |
   |--------------------------+----------------------------|
   | Parent Process ID (PPID) | Process (parent) that      |
   |                          | started this process       |
   |--------------------------+----------------------------|
   | Thread ID (TID)          | This is the same as the    |
   |                          | PID for single-threaded    |
   |                          | processes. For a multi     |
   |                          | threaded process, each     |
   |                          | thread shares the same PID |
   |                          | but has a unique TID.      |
   |--------------------------+----------------------------|

** Listing processes
   *ps* program provides information about the currently running
   processes keyed by *PID*. Which process to examine, what
   information to display and precisely what should be the output
   format, all these things can be specified by various options.
   
   Example:
   1. To display all processes running under the current shell:
      #+BEGIN_EXAMPLE
      $ ps
        PID TTY          TIME CMD
      2875 pts/7    00:00:00 bash
      2989 pts/7    00:00:54 emacs
      3804 pts/7    00:00:00 ps
      #+END_EXAMPLE
   2. To display information of processes for a specified username,
      use command with =-u= option:
      #+BEGIN_EXAMPLE
      $ ps -u
      #+END_EXAMPLE
   3. To display all the processes in the system in full detail, use
      command with =-ef= option:
      #+BEGIN_EXAMPLE
      $ ps -ef
      #+END_EXAMPLE
   4. To display all the processes along with their threads use ps
      command with =-eLf= option:
      #+BEGIN_EXAMPLE
      $ ps -eLf
      #+END_EXAMPLE
   5. To display all the processes for all the users use ps command
      with =aux= option:
      #+BEGIN_EXAMPLE
      $ ps aux
      #+END_EXAMPLE

** Process tree
   At some point one of our applications may stop working
   properly. Then to view the relationship of the application process
   with its parent and siblings we can use =pstree= command.
   
   =pstree= displays processes running on the system in the form of
   a *tree diagram* showing the relationship between a process and its
   parent process and its siblings. *Threads* are displayed in curly
   braces.

   To terminate process we can use =kill -p <pid>= command or =kill
   -SIGKILL <pid>= command. A user can only kill processes belonging
   to him, processes belonging to another user are off limits. However
   a root can kill other user's processes also.

** Live system monitoring using top command
   *top* command displays constant real-time updates (every two
   seconds) by default. *top* clearly highlights which processes are
   consuming the most CPU cycles and memory.

*** First line of top output
    #+BEGIN_EXAMPLE
    top - 09:06:31 up 53 min,  3 users,  load average: 0.14, 0.24, 0.28
    #+END_EXAMPLE

    - how long the system has been up
    - how many users are logged on
    - what is the load average

    The load average describes how busy the system is. A load average
    of 1.00 per cpu indicates a fully subscribed, but not overloaded
    system. If the load average is greater than *1*, that means
    processes are competing for CPU time. If the load average is very
    high that might indicate that the system is having a problem,
    such as runaway process.

*** Second line of top output
    #+BEGIN_EXAMPLE
    Tasks: 210 total,   2 running, 208 sleeping,   0 stopped,   0 zombie
    #+END_EXAMPLE

    The second line of top command displays the total number of
    processes, the number of running, sleeping, stopped and zombie
    processes. Comparing the number of running processes with the load
    average helps determine if the system has reached its capacity or
    perhaps a particular user is running too many processes.
*** Third line of top output
    #+BEGIN_EXAMPLE
    %Cpu(s):  2.1 us,  1.2 sy,  0.0 ni, 96.2 id,  0.5 wa,  0.0 hi,  0.0 si,  0.0 st
    #+END_EXAMPLE
    Third line of the top output indicates how the CPU time is divided
    between the users (*us*) and kernel (*sy*) by displaying the
    percentage of CPU time used for each.

    Then percentage of user jobs running at a lower priority
    (niceness - *ni*) is then listed. Then percentage of cpu idle time
    (*id*) is displayed. Idle mode should be low if load average is
    high and vice versa. Then percentage of jobs waiting (*wa*) for
    I/O is listed. Interrupts include the percentage of hardware
    (*hi*) vs. software interrupts (*si*). Steal time (*st*) is
    generally used with virtual machines, which has some of its idle
    CPU time taken for other uses.

*** Fourth and Fifth line of top output
    #+BEGIN_EXAMPLE
    KiB Mem:   3932648 total,  1931168 used,  2001480 free,   120424 buffers
    KiB Swap:  8388604 total,        0 used,  8388604 free.   895892 cached Mem
    #+END_EXAMPLE
    
    The fourth and fifth line displays memory usage. This is divided
    into two categories:
    - Physical memory (RAM) - displayed on line 4
    - Swap space - displayed on line 5

    Both categories display total available space, used space, free
    space.

    Memory usage should be monitored carefully to ensure good system
    performance. Once the physical memory is exhausted system starts
    using swap space, and since accessing disk is much slower than
    accessing RAM, this will negatively affect system
    performance. 

    If the system starts using swap more often, we can add more swap
    space. However, adding more physical RAM should also be
    considered.

*** Process list of the top output
    #+BEGIN_EXAMPLE
    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
    1501 root      20   0  391340  67052  56672 S   0.7  1.7   0:52.12 Xorg
    2617 yogesh    20   0 1182252 343052  66556 S   0.7  8.7   0:47.23 firefox
    #+END_EXAMPLE

    Each line in the process list displays information about a
    process. By default processes are ordered by highest CPU
    usage. Following parameters about each process are displayed:
    - Process ID (PID)
    - Process owner (USER)
    - Priority (PR) and nice value (NI)
    - Virtual (VIRT), physical (RES) and shared memory (SHR)
    - Status (S)
    - Percentage CPU (%CPU) and memory (%MEM) used
    - Execution time (TIME+)
    - Command (COMMAND)

*** Interactive keys with top
    Besides reporting information, *top* can be utilized interactively
    for monitoring and controlling processes. While top is running in
    a terminal window we can enter single-letter commands to change
    its behavior. For example we can view the top-ranked processes
    based on CPU or memory usage. If needed, we can alter the
    priorities of running processes or we can stop/kill a process.
    
* Load averages
  Load average is the average of load number for a given period of
  time. It takes into account processes that are:

  1. Actively running on a CPU.
  2. Waiting for a CPU to become available
  3. Sleeping; i.e. waiting for some kind of resource (typically,
     I/O) to become available.
     
  The load average can be obtained by running *w*, *top* or *uptime*
  command.

  The load average is displayed using three sets of numbers as shown
  below:
  #+BEGIN_EXAMPLE
  19:42:37 up 22 min,  3 users,  load average: 0.34, 0.35, 0.31
  #+END_EXAMPLE

  Assuming our system is a single cpu system, the 0.31 means that for
  past one minute, on average, the system has been 31%
  utilized. Number in the next position 0.35 indicates that over past
  5 minute, on average, the system has been 35% utilized. Number in
  the next position 0.34 indicates that over past 15 minutes, on
  average, the system has been 34% utilized.

  If we see a 1.0 in the second position that means the single-CPU
  system has been 100% utilized over past 5 minutes. If the number is
  greater than 1.0 that means CPU was over utilized, and there were
  processes waiting for CPU to be free.

  If we had more than one CPU, say a quad-CPU system, we would divide
  the load average numbers by the number of CPU. For example seeing a
  1 minute load average of 4.00 implies that the system as a whole was
  100% (4.0/4) utilized during the last minute.

  Short term increases are usually not a problem. A high peak we see
  is likely a burst of activity, not a new level. For example at
  startup, many processes starts, and then activity settles down. But
  if a high peek is seen over past 5 and 15 minutes load averages,
  then its a matter of concern.

* Background and Foreground Processes
  Linux allows foreground and background job processing. Foreground
  jobs run directly from the shell, when one job is running other job
  has to wait for the shell access.

  The background processes run with lower priority, and returns shell
  for further execution of command. Running processes in the
  background is useful when the execution time is high, and we could
  rather use that time for other processing.

  By default processes are executed in foreground. We can run a job in
  the background by suffixing =&= to the command.
  #+BEGIN_EXAMPLE
  updatedb &
  #+END_EXAMPLE

  We can do =ctrl-z= to suspend a foreground job or =ctrl-c= to
  terminate a foreground job and can always use the =bg= and =fg=
  command to run a process in background and foreground respectively.
  #+BEGIN_EXAMPLE
  root@machine:~# updatedb &
  [1] 3755
  root@machine:~# sleep 100
  ^Z[1]   Done                    updatedb
  
  [2]+  Stopped                 sleep 100
  root@machine:~# bg
  [2]+ sleep 100 &
  root@machine:~# fg
  sleep 100
  ^C
  root@machine:~# 
  #+END_EXAMPLE

  To bring a particular into background or foreground, we can specify
  the job id of the job in the command as follows. job id can be found
  using =jobs= command described below.
  #+BEGIN_EXAMPLE
  $ fg %1
  $ bg %1
  #+END_EXAMPLE

* Managing jobs
  The =jobs= utility displays all jobs running in background, with
  their job id, state and command.
  #+BEGIN_EXAMPLE
  [1]-  Running                 emacs linux-foundation-course.org &
  [2]+  Stopped                 sleep 100
  #+END_EXAMPLE
  
  =jobs -l= command provides jobs listing with their process id as
  well.
  #+BEGIN_EXAMPLE
  [1]+  3369 Running                 emacs linux-foundation-course.org &
  #+END_EXAMPLE

  The background jobs are connected to the terminal window, so the
  =jobs= utility will only shows jobs started for the same terminal.
  
  #+BEGIN_EXAMPLE
  $ (date; sleep 60; date; sleep 180; date) > output.txt
  $ jobs
  [1]-  Running                 emacs linux-foundation-course.org &
  [2]+  Running                 ( date; sleep 60; date; sleep 180; date ) > output.txt &
  $ fg %2
  ( date; sleep 60; date; sleep 180; date ) > output.txt  
  ^Z
  [2]+  Stopped                 ( date; sleep 60; date; sleep 180; date ) > output.txt
  yogesh@machine:~/work/projects/linux-system-administration/linux$ jobs
  [1]-  Running                 emacs linux-foundation-course.org &
  [2]+  Stopped                 ( date; sleep 60; date; sleep 180; date ) > output.txt
  $ bg %2
  [2]+ ( date; sleep 60; date; sleep 180; date ) > output.txt &
  yogesh@machine:~/work/projects/linux-system-administration/linux$ jobs
  [1]-  Running                 emacs linux-foundation-course.org &
  [2]+  Running                 ( date; sleep 60; date; sleep 180; date ) > output.txt &
  $ kill %2
  yogesh@machine:~/work/projects/linux-system-administration/linux$ jobs
  [1]-  Running                 emacs linux-foundation-course.org &
  [2]+  Terminated              ( date; sleep 60; date; sleep 180; date ) > output.txt
  yogesh@machine:~/work/projects/linux-system-administration/linux$ jobs
  [1]+  Running                 emacs linux-foundation-course.org &
  #+END_EXAMPLE

* Scheduling future processes
** at
   We can schedule non-interactive tasks to run in future using =at=
   command.
   #+BEGIN_EXAMPLE
   $ at 22:36
   warning: commands will be executed using /bin/sh
   at> ls
   at> <EOT>
   job 5 at Wed Jul 27 22:36:00 2016
   #+END_EXAMPLE
   
   #+BEGIN_EXAMPLE
   $ at now + 10 minutes
   warning: commands will be executed using /bin/sh
   at> bash pintest.sh
   at> <EOT>
   job 8 at Fri Jul 29 08:53:00 2016
   #+END_EXAMPLE
   
** cron
   cron is a time-based program used to launch routine background jobs
   at specific time. It is driven by a configuration file
   =/etc/crontab=, which contains the shell commands that are to be
   run at a scheduled time. 

   There is a system wide configuration file as well as individual
   user level. File at =/etc/crontab= is a system level configuration
   file. There is a one file for each user's crontab under
   =/var/spool/cron/crontabs= directory.

   Each line of crontab file is composed of cron expression, which
   decides the scheduled time followed by a shell command to execute.

   =crontab= command maintains crontab files for individual users.
   =crontab -e= command will open the configuration file to edit the
   existing command or to add new commands to the crontab. After we
   exit from the editor crontab will be installed automatically.

   Each line will have following six fields:
   |--------+----------------------------+------------------------|
   | *Field | Description                |                 Value* |
   |--------+----------------------------+------------------------|
   | MIN    | Scheduled minute           |                   0-59 |
   |--------+----------------------------+------------------------|
   | HOUR   | Scheduled hour             |                   0-23 |
   |--------+----------------------------+------------------------|
   | DOM    | Scheduled day of the month |                   1-31 |
   |--------+----------------------------+------------------------|
   | MON    | Scheduled month            |                   1-12 |
   |--------+----------------------------+------------------------|
   | DOW    | Scheduled day of the week  |          0-6(0=sunday) |
   |--------+----------------------------+------------------------|
   | CMD    | Command to run             | Any command to execute |
   |--------+----------------------------+------------------------|

   1. Following entry in crontab schedules the job to run every minute
      of every hour of every day of the month, and every month and
      every day in the week.
      #+BEGIN_EXAMPLE
      * * * * * /usr/bin/script.sh
      #+END_EXAMPLE

  2. Following entry in crontab schedules the job to run at 08:30 on
     1st Jan, irrespective of the day of the week.
     #+BEGIN_EXAMPLE
     30 08 1 2 * /home/sys-admin/full-backup
     #+END_EXAMPLE

  3. Add a cron job to crontab.
     #+BEGIN_EXAMPLE
     $ crontab -l
     $ cat mycron 
     0 10 * * * ping google.com
     $ crontab mycron 
     $ crontab -l
     0 10 * * * ping google.com
     #+END_EXAMPLE

** sleep
   Sometimes a job must be suspended/delayed from the execution. For
   example suppose a process has read and processed the data, and now
   needs to save a report on a backup system, backup system may not be
   ready yet, then the process can be made to sleep(wait) until the
   device is ready.

   *sleep* suspends execution for at least the specified period of
   time, which can be given as the number of seconds, minutes, hours
   or days. After that time has passed, or interrupting signal is
   received the process will resume execution.
   
   #+BEGIN_EXAMPLE
   sleep NUMBER[SUFFIX]
   #+END_EXAMPLE
   Where suffix may be:
   1. =s= for seconds(the default)
   2. =m= for minutes
   3. =h= for hours
   4. =d= for days

   *sleep* and *at* commands are different, =sleep= command suspends
   the execution for a specified period of time, whereas =at= command
   start the execution at the specified time.

   Example: Create a reminder for a meeting at 10 mins from now.
   #+BEGIN_EXAMPLE
   $ (sleep 600; echo "meeting")
   #+END_EXAMPLE

* Learning
** rm: remove write-protected regular empty file ?
   To remove a file, we need write permission on the parent directory.

** grep stderr
   #+BEGIN_EXAMPLE
   command 2>&1 > /dev/null | grep something
   #+END_EXAMPLE
** SUID, SGID, and sticky bit
*** SUID
    set user ID. Example
    #+BEGIN_EXAMPLE
    $ ls -l /bin/ping
    -rwsr-xr-x 1 root root 44168 May  8  2014 /bin/ping
    #+END_EXAMPLE
    This permission is denoted by =s= bit. When this bit is set, then
    when other users run the program, the process will run as the
    owner of the file.

    Modifying SUID
    #+BEGIN_EXAMPLE
    chmod u+s myfile
    chmod 4755 myfile
    #+END_EXAMPLE

    The SUID is denoted by a 4 and pre-pended to the permission
    set. We may see the SUID denoted as a capital =S=, this means that
    it still does the same thing, but it does not have execute
    permissions.

*** SGID
    set group ID. When this bit is set, then when other users run the
    program, the process will run as member of the group of the
    program.

    #+BEGIN_EXAMPLE
    $ ls -l /usr/bin/wall
    -rwxr-sr-x 1 root tty 19024 Sep  3  2015 /usr/bin/wall
    #+END_EXAMPLE

    Modifying SGID

    #+BEGIN_EXAMPLE
    chmod g+s myfile
    chmod 2555 myfile
    #+END_EXAMPLE

    The numerical representation for SGID is 2.

*** Sticky bit
    When sticky bit is set, the file can only be deleted by the owner
    of the file. The directory permissions won't have affect on the
    file permissions. It is denoted by "t".
    #+BEGIN_EXAMPLE
    $ ls -l /tmp
    drwxrwxrwt   6 root root  4096 Apr  3 12:35 tmp
    #+END_EXAMPLE

** umask
   Every file gets created with a default set of permissions. We can
   modify this default permission, by setting the =umask=.

   Instead of adding permissions, umask removes specified permissions.
   Example: Following umask means, allow owners to access everything,
   for groups, take away their write permission, and for others take
   away their write permission.

   #+BEGIN_EXAMPLE
   $ touch a.txt
   $ ls -l a.txt
   -rw-rw-r-- 1 yogesh yogesh 0 Apr  3 13:28 a.txt
   $ umask 022
   $ touch b.txt
   $ ls -l b.txt
   -rw-r--r-- 1 yogesh yogesh 0 Apr  3 13:29 b.txt
   #+END_EXAMPLE

** File System
   - One viewpoint is the structure of file systems.
   - Second point is maintaining enough free space in our file system
     for trouble free operations.
   - File systems need to be located on devices that can be read from
     and written to at random locations. These devices are disks.
   - A clear understanding of the *fsck* program's operation will
     solidify the understanding of the file system and its parts.
   - UNIX system handles the complex affair of controlling different
     types of disks through device drivers written by system
     programmers.

* COMMENT TODO
  - Proposed plan to do this course is to spend daily one hour
    attending classes.
  - Revise ch-3 boot process again at the end of the course.
  - Learn why Linux is virus secured. Are there any anti-virus systems
    for Linux. refer [[Process Isolation]]
  - Read about National Security Agency.
  - Try out boot loader password.
  - Understand sgid and suid properly.
  - try in a test machine
    #+BEGIN_EXAMPLE
    ln -s /etc/passwd /tmp/tempfile
    echo "test" > /tmp/tempfile
    #+END_EXAMPLE
  - Revise processes
* Reference
  - http://linuxcommand.org/tlcl.php (resource for commands help)
  - https://www.centos.org/docs/ (centos documentaion)
  - http://refspecs.linuxfoundation.org/fhs.shtml (file system)
  - https://courses.edx.org/asset-v1:LinuxFoundationX+LFS101x+1T2016+type@asset+block/LFS101_Ch3_Sec1_FSH.pdf
    (filesystem)
  - http://www.pathname.com/fhs/pub/fhs-2.3.pdf (Filesystem hierarchy
    standard
  - http://askubuntu.com/a/801191/499885 (hard vs soft link)
  - https://linuxjourney.com
  - https://web.archive.org/web/20150108210426/http://content.hccfl.edu/pollock/aunix1/filepermissions.htm
  - http://opengroup.org/unix
